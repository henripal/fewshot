{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import fewshot.data\n",
    "import fewshot.trainer\n",
    "import fewshot.focal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and results on large dataset\n",
    "\n",
    "This notebook contains the training and results for the fashion dataset, as well as all the different \"tricks\" to improve classification accuracy on the rare classes.\n",
    "\n",
    "NB: I did a little bit of hyperparameter optimization \"offline\" - mostly around the learning rate, gamma for the focal loss, which number of epochs was appropriate, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot.data.fix_quotes('../data/fashion-dataset/styles.csv', '../data/fashion-dataset/styles_quoted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/small/styles_quoted.csv',\n",
    "                                '../data/small/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "## replacing the last layer with the dense layer we need\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which loss performs better on top20?\n",
    "### Plain Cross-Entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n",
      "Training loss: 0.732\n",
      "Validation loss: 1.064\n",
      "Validation accuracy: 0.737\n",
      "------------- epoch:  1\n",
      "Training loss: 0.450\n",
      "Validation loss: 0.975\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  2\n",
      "Training loss: 0.386\n",
      "Validation loss: 0.976\n",
      "Validation accuracy: 0.795\n",
      "------------- epoch:  3\n",
      "Training loss: 0.349\n",
      "Validation loss: 1.057\n",
      "Validation accuracy: 0.816\n",
      "------------- epoch:  4\n",
      "Training loss: 0.320\n",
      "Validation loss: 0.821\n",
      "Validation accuracy: 0.817\n",
      "------------- epoch:  5\n",
      "Training loss: 0.281\n",
      "Validation loss: 1.153\n",
      "Validation accuracy: 0.792\n",
      "------------- epoch:  6\n",
      "Training loss: 0.284\n",
      "Validation loss: 0.853\n",
      "Validation accuracy: 0.840\n",
      "------------- epoch:  7\n",
      "Training loss: 0.259\n",
      "Validation loss: 0.959\n",
      "Validation accuracy: 0.837\n",
      "------------- epoch:  8\n",
      "Training loss: 0.241\n",
      "Validation loss: 0.900\n",
      "Validation accuracy: 0.842\n",
      "------------- epoch:  9\n",
      "Training loss: 0.243\n",
      "Validation loss: 0.930\n",
      "Validation accuracy: 0.832\n",
      "------------- epoch:  10\n",
      "Training loss: 0.225\n",
      "Validation loss: 1.335\n",
      "Validation accuracy: 0.739\n",
      "------------- epoch:  11\n",
      "Training loss: 0.221\n",
      "Validation loss: 1.120\n",
      "Validation accuracy: 0.825\n",
      "------------- epoch:  12\n",
      "Training loss: 0.209\n",
      "Validation loss: 1.035\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  13\n",
      "Training loss: 0.208\n",
      "Validation loss: 0.962\n",
      "Validation accuracy: 0.847\n",
      "------------- epoch:  14\n",
      "Training loss: 0.205\n",
      "Validation loss: 1.031\n",
      "Validation accuracy: 0.839\n",
      "------------- epoch:  15\n",
      "Training loss: 0.182\n",
      "Validation loss: 0.947\n",
      "Validation accuracy: 0.857\n",
      "------------- epoch:  16\n",
      "Training loss: 0.187\n",
      "Validation loss: 0.985\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  17\n",
      "Training loss: 0.181\n",
      "Validation loss: 0.904\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  18\n",
      "Training loss: 0.169\n",
      "Validation loss: 0.982\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  19\n",
      "Training loss: 0.166\n",
      "Validation loss: 1.040\n",
      "Validation accuracy: 0.846\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      89.1      99.2\n",
      "Shirts                       98.3     100.0\n",
      "Casual Shoes                 86.6      98.3\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 73.9     100.0\n",
      "Kurtas                       94.9      99.1\n",
      "Tops                         66.7     100.0\n",
      "Handbags                     95.0      99.2\n",
      "Heels                        89.7      99.1\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      95.7      99.1\n",
      "Flip Flops                   87.6      96.5\n",
      "Sandals                      78.4     100.0\n",
      "Briefs                       95.5     100.0\n",
      "Belts                        97.3      99.1\n",
      "Backpacks                    84.2      99.1\n",
      "Socks                        77.3      93.8\n",
      "Formal Shoes                 77.8      99.1\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      84.4      94.1\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0014/model_epoch_18.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.463\n",
      "Validation loss: 0.766\n",
      "Validation accuracy: 0.690\n",
      "------------- epoch:  1\n",
      "Training loss: 0.274\n",
      "Validation loss: 0.628\n",
      "Validation accuracy: 0.772\n",
      "------------- epoch:  2\n",
      "Training loss: 0.209\n",
      "Validation loss: 0.604\n",
      "Validation accuracy: 0.779\n",
      "------------- epoch:  3\n",
      "Training loss: 0.173\n",
      "Validation loss: 0.640\n",
      "Validation accuracy: 0.788\n",
      "------------- epoch:  4\n",
      "Training loss: 0.159\n",
      "Validation loss: 0.620\n",
      "Validation accuracy: 0.774\n",
      "------------- epoch:  5\n",
      "Training loss: 0.155\n",
      "Validation loss: 0.636\n",
      "Validation accuracy: 0.791\n",
      "------------- epoch:  6\n",
      "Training loss: 0.133\n",
      "Validation loss: 0.528\n",
      "Validation accuracy: 0.831\n",
      "------------- epoch:  7\n",
      "Training loss: 0.133\n",
      "Validation loss: 0.625\n",
      "Validation accuracy: 0.810\n",
      "------------- epoch:  8\n",
      "Training loss: 0.117\n",
      "Validation loss: 0.631\n",
      "Validation accuracy: 0.814\n",
      "------------- epoch:  9\n",
      "Training loss: 0.127\n",
      "Validation loss: 0.581\n",
      "Validation accuracy: 0.833\n",
      "------------- epoch:  10\n",
      "Training loss: 0.106\n",
      "Validation loss: 0.588\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  11\n",
      "Training loss: 0.116\n",
      "Validation loss: 0.656\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  12\n",
      "Training loss: 0.102\n",
      "Validation loss: 0.551\n",
      "Validation accuracy: 0.842\n",
      "------------- epoch:  13\n",
      "Training loss: 0.105\n",
      "Validation loss: 0.620\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  14\n",
      "Training loss: 0.102\n",
      "Validation loss: 0.706\n",
      "Validation accuracy: 0.797\n",
      "------------- epoch:  15\n",
      "Training loss: 0.091\n",
      "Validation loss: 0.596\n",
      "Validation accuracy: 0.831\n",
      "------------- epoch:  16\n",
      "Training loss: 0.081\n",
      "Validation loss: 0.702\n",
      "Validation accuracy: 0.844\n",
      "------------- epoch:  17\n",
      "Training loss: 0.083\n",
      "Validation loss: 0.606\n",
      "Validation accuracy: 0.853\n",
      "------------- epoch:  18\n",
      "Training loss: 0.083\n",
      "Validation loss: 0.645\n",
      "Validation accuracy: 0.836\n",
      "------------- epoch:  19\n",
      "Training loss: 0.094\n",
      "Validation loss: 0.610\n",
      "Validation accuracy: 0.840\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      95.0     100.0\n",
      "Shirts                       98.3     100.0\n",
      "Casual Shoes                 84.0      99.2\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 89.1     100.0\n",
      "Kurtas                       96.6      99.1\n",
      "Tops                         48.7      99.1\n",
      "Handbags                     84.9      99.2\n",
      "Heels                        93.2     100.0\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      96.6     100.0\n",
      "Flip Flops                   83.2      98.2\n",
      "Sandals                      69.0     100.0\n",
      "Briefs                      100.0     100.0\n",
      "Belts                        99.1     100.0\n",
      "Backpacks                    97.4     100.0\n",
      "Socks                        87.6     100.0\n",
      "Formal Shoes                 74.1     100.0\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      84.8      94.7\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0053/model_epoch_17.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighed Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n",
      "Training loss: 0.913\n",
      "Validation loss: 0.793\n",
      "Validation accuracy: 0.728\n",
      "------------- epoch:  1\n",
      "Training loss: 0.545\n",
      "Validation loss: 0.656\n",
      "Validation accuracy: 0.698\n",
      "------------- epoch:  2\n",
      "Training loss: 0.446\n",
      "Validation loss: 0.570\n",
      "Validation accuracy: 0.767\n",
      "------------- epoch:  3\n",
      "Training loss: 0.387\n",
      "Validation loss: 0.699\n",
      "Validation accuracy: 0.787\n",
      "------------- epoch:  4\n",
      "Training loss: 0.370\n",
      "Validation loss: 0.493\n",
      "Validation accuracy: 0.808\n",
      "------------- epoch:  5\n",
      "Training loss: 0.312\n",
      "Validation loss: 0.489\n",
      "Validation accuracy: 0.781\n",
      "------------- epoch:  6\n",
      "Training loss: 0.315\n",
      "Validation loss: 0.514\n",
      "Validation accuracy: 0.810\n",
      "------------- epoch:  7\n",
      "Training loss: 0.306\n",
      "Validation loss: 0.506\n",
      "Validation accuracy: 0.802\n",
      "------------- epoch:  8\n",
      "Training loss: 0.271\n",
      "Validation loss: 0.474\n",
      "Validation accuracy: 0.808\n",
      "------------- epoch:  9\n",
      "Training loss: 0.270\n",
      "Validation loss: 0.524\n",
      "Validation accuracy: 0.806\n",
      "------------- epoch:  10\n",
      "Training loss: 0.255\n",
      "Validation loss: 0.440\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  11\n",
      "Training loss: 0.254\n",
      "Validation loss: 0.411\n",
      "Validation accuracy: 0.825\n",
      "------------- epoch:  12\n",
      "Training loss: 0.239\n",
      "Validation loss: 0.423\n",
      "Validation accuracy: 0.828\n",
      "------------- epoch:  13\n",
      "Training loss: 0.230\n",
      "Validation loss: 0.422\n",
      "Validation accuracy: 0.833\n",
      "------------- epoch:  14\n",
      "Training loss: 0.229\n",
      "Validation loss: 0.477\n",
      "Validation accuracy: 0.799\n",
      "------------- epoch:  15\n",
      "Training loss: 0.219\n",
      "Validation loss: 0.446\n",
      "Validation accuracy: 0.845\n",
      "------------- epoch:  16\n",
      "Training loss: 0.199\n",
      "Validation loss: 0.497\n",
      "Validation accuracy: 0.815\n",
      "------------- epoch:  17\n",
      "Training loss: 0.200\n",
      "Validation loss: 0.446\n",
      "Validation accuracy: 0.838\n",
      "------------- epoch:  18\n",
      "Training loss: 0.199\n",
      "Validation loss: 0.418\n",
      "Validation accuracy: 0.841\n",
      "------------- epoch:  19\n",
      "Training loss: 0.189\n",
      "Validation loss: 0.478\n",
      "Validation accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(weight=torch.tensor(data.weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      94.1     100.0\n",
      "Shirts                       97.5     100.0\n",
      "Casual Shoes                 78.2      98.3\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 88.2     100.0\n",
      "Kurtas                       93.2      99.1\n",
      "Tops                         61.5      99.1\n",
      "Handbags                     93.3      98.3\n",
      "Heels                        81.2      99.1\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      94.0     100.0\n",
      "Flip Flops                   95.6      97.3\n",
      "Sandals                      69.0     100.0\n",
      "Briefs                       93.3     100.0\n",
      "Belts                        99.1      99.1\n",
      "Backpacks                    87.7      98.2\n",
      "Socks                        86.6      94.8\n",
      "Formal Shoes                 83.3      99.1\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      84.7      94.1\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0136/model_epoch_15.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighed Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.575\n",
      "Validation loss: 0.498\n",
      "Validation accuracy: 0.682\n",
      "------------- epoch:  1\n",
      "Training loss: 0.322\n",
      "Validation loss: 0.403\n",
      "Validation accuracy: 0.736\n",
      "------------- epoch:  2\n",
      "Training loss: 0.254\n",
      "Validation loss: 0.321\n",
      "Validation accuracy: 0.748\n",
      "------------- epoch:  3\n",
      "Training loss: 0.229\n",
      "Validation loss: 0.272\n",
      "Validation accuracy: 0.803\n",
      "------------- epoch:  4\n",
      "Training loss: 0.220\n",
      "Validation loss: 0.242\n",
      "Validation accuracy: 0.822\n",
      "------------- epoch:  5\n",
      "Training loss: 0.194\n",
      "Validation loss: 0.296\n",
      "Validation accuracy: 0.800\n",
      "------------- epoch:  6\n",
      "Training loss: 0.179\n",
      "Validation loss: 0.255\n",
      "Validation accuracy: 0.792\n",
      "------------- epoch:  7\n",
      "Training loss: 0.166\n",
      "Validation loss: 0.239\n",
      "Validation accuracy: 0.824\n",
      "------------- epoch:  8\n",
      "Training loss: 0.151\n",
      "Validation loss: 0.276\n",
      "Validation accuracy: 0.785\n",
      "------------- epoch:  9\n",
      "Training loss: 0.155\n",
      "Validation loss: 0.417\n",
      "Validation accuracy: 0.748\n",
      "------------- epoch:  10\n",
      "Training loss: 0.161\n",
      "Validation loss: 0.258\n",
      "Validation accuracy: 0.817\n",
      "------------- epoch:  11\n",
      "Training loss: 0.148\n",
      "Validation loss: 0.239\n",
      "Validation accuracy: 0.811\n",
      "------------- epoch:  12\n",
      "Training loss: 0.139\n",
      "Validation loss: 0.284\n",
      "Validation accuracy: 0.825\n",
      "------------- epoch:  13\n",
      "Training loss: 0.129\n",
      "Validation loss: 0.291\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  14\n",
      "Training loss: 0.131\n",
      "Validation loss: 0.230\n",
      "Validation accuracy: 0.846\n",
      "------------- epoch:  15\n",
      "Training loss: 0.121\n",
      "Validation loss: 0.293\n",
      "Validation accuracy: 0.797\n",
      "------------- epoch:  16\n",
      "Training loss: 0.115\n",
      "Validation loss: 0.316\n",
      "Validation accuracy: 0.804\n",
      "------------- epoch:  17\n",
      "Training loss: 0.125\n",
      "Validation loss: 0.241\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  18\n",
      "Training loss: 0.119\n",
      "Validation loss: 0.230\n",
      "Validation accuracy: 0.837\n",
      "------------- epoch:  19\n",
      "Training loss: 0.106\n",
      "Validation loss: 0.226\n",
      "Validation accuracy: 0.840\n",
      "------------- epoch:  20\n",
      "Training loss: 0.100\n",
      "Validation loss: 0.255\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  21\n",
      "Training loss: 0.107\n",
      "Validation loss: 0.232\n",
      "Validation accuracy: 0.832\n",
      "------------- epoch:  22\n",
      "Training loss: 0.093\n",
      "Validation loss: 0.244\n",
      "Validation accuracy: 0.837\n",
      "------------- epoch:  23\n",
      "Training loss: 0.097\n",
      "Validation loss: 0.208\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  24\n",
      "Training loss: 0.092\n",
      "Validation loss: 0.252\n",
      "Validation accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "normalized_weights = data.n_classes *data.weights /sum(data.weights)\n",
    "\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=.5, alpha=torch.tensor(normalized_weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 25, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      87.4     100.0\n",
      "Shirts                       99.2     100.0\n",
      "Casual Shoes                 81.5      99.2\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 82.4      98.3\n",
      "Kurtas                       88.0     100.0\n",
      "Tops                         76.1     100.0\n",
      "Handbags                     84.9      99.2\n",
      "Heels                        74.4      98.3\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      95.7     100.0\n",
      "Flip Flops                   96.5      97.3\n",
      "Sandals                      61.2     100.0\n",
      "Briefs                       95.5     100.0\n",
      "Belts                       100.0     100.0\n",
      "Backpacks                    97.4     100.0\n",
      "Socks                        90.7      99.0\n",
      "Formal Shoes                 95.4      98.1\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        98.1      99.1\n",
      "===========================================\n",
      "Average                      85.2      94.4\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0231/model_epoch_19.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the *Weighed Focal Loss* performs best here, although the difference between the models could still be due to noise, we're going to run with it and use this model to finetune on the rare classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning on the rare classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/fashion-dataset/styles_quoted.csv',\n",
    "                                '../data/fashion-dataset/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0231/model_epoch_19.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "num_ftrs = model.fc.in_features\n",
    "## replacing the last layer with the dense layer we need\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.773\n",
      "Validation loss: 0.778\n",
      "Validation accuracy: 0.184\n",
      "------------- epoch:  1\n",
      "Training loss: 0.499\n",
      "Validation loss: 0.632\n",
      "Validation accuracy: 0.235\n",
      "------------- epoch:  2\n",
      "Training loss: 0.367\n",
      "Validation loss: 0.577\n",
      "Validation accuracy: 0.305\n",
      "------------- epoch:  3\n",
      "Training loss: 0.304\n",
      "Validation loss: 0.561\n",
      "Validation accuracy: 0.312\n",
      "------------- epoch:  4\n",
      "Training loss: 0.249\n",
      "Validation loss: 0.531\n",
      "Validation accuracy: 0.308\n",
      "------------- epoch:  5\n",
      "Training loss: 0.210\n",
      "Validation loss: 0.573\n",
      "Validation accuracy: 0.249\n",
      "------------- epoch:  6\n",
      "Training loss: 0.203\n",
      "Validation loss: 0.641\n",
      "Validation accuracy: 0.241\n",
      "------------- epoch:  7\n",
      "Training loss: 0.197\n",
      "Validation loss: 0.615\n",
      "Validation accuracy: 0.301\n",
      "------------- epoch:  8\n",
      "Training loss: 0.180\n",
      "Validation loss: 0.590\n",
      "Validation accuracy: 0.322\n",
      "------------- epoch:  9\n",
      "Training loss: 0.135\n",
      "Validation loss: 0.610\n",
      "Validation accuracy: 0.396\n",
      "------------- epoch:  10\n",
      "Training loss: 0.121\n",
      "Validation loss: 0.632\n",
      "Validation accuracy: 0.372\n",
      "------------- epoch:  11\n",
      "Training loss: 0.106\n",
      "Validation loss: 0.683\n",
      "Validation accuracy: 0.355\n",
      "------------- epoch:  12\n",
      "Training loss: 0.099\n",
      "Validation loss: 0.760\n",
      "Validation accuracy: 0.370\n",
      "------------- epoch:  13\n",
      "Training loss: 0.105\n",
      "Validation loss: 0.617\n",
      "Validation accuracy: 0.391\n",
      "------------- epoch:  14\n",
      "Training loss: 0.086\n",
      "Validation loss: 0.658\n",
      "Validation accuracy: 0.406\n",
      "------------- epoch:  15\n",
      "Training loss: 0.080\n",
      "Validation loss: 0.744\n",
      "Validation accuracy: 0.412\n",
      "------------- epoch:  16\n",
      "Training loss: 0.072\n",
      "Validation loss: 0.786\n",
      "Validation accuracy: 0.379\n",
      "------------- epoch:  17\n",
      "Training loss: 0.094\n",
      "Validation loss: 0.828\n",
      "Validation accuracy: 0.398\n",
      "------------- epoch:  18\n",
      "Training loss: 0.099\n",
      "Validation loss: 0.690\n",
      "Validation accuracy: 0.384\n",
      "------------- epoch:  19\n",
      "Training loss: 0.100\n",
      "Validation loss: 0.832\n",
      "Validation accuracy: 0.337\n",
      "------------- epoch:  20\n",
      "Training loss: 0.081\n",
      "Validation loss: 0.799\n",
      "Validation accuracy: 0.387\n",
      "------------- epoch:  21\n",
      "Training loss: 0.070\n",
      "Validation loss: 0.706\n",
      "Validation accuracy: 0.355\n",
      "------------- epoch:  22\n",
      "Training loss: 0.064\n",
      "Validation loss: 0.897\n",
      "Validation accuracy: 0.422\n",
      "------------- epoch:  23\n",
      "Training loss: 0.055\n",
      "Validation loss: 0.814\n",
      "Validation accuracy: 0.423\n",
      "------------- epoch:  24\n",
      "Training loss: 0.056\n",
      "Validation loss: 0.879\n",
      "Validation accuracy: 0.408\n",
      "------------- epoch:  25\n",
      "Training loss: 0.052\n",
      "Validation loss: 0.693\n",
      "Validation accuracy: 0.412\n",
      "------------- epoch:  26\n",
      "Training loss: 0.043\n",
      "Validation loss: 0.778\n",
      "Validation accuracy: 0.432\n",
      "------------- epoch:  27\n",
      "Training loss: 0.041\n",
      "Validation loss: 0.985\n",
      "Validation accuracy: 0.399\n",
      "------------- epoch:  28\n",
      "Training loss: 0.070\n",
      "Validation loss: 0.858\n",
      "Validation accuracy: 0.385\n",
      "------------- epoch:  29\n",
      "Training loss: 0.090\n",
      "Validation loss: 0.736\n",
      "Validation accuracy: 0.305\n",
      "------------- epoch:  30\n",
      "Training loss: 0.154\n",
      "Validation loss: 0.890\n",
      "Validation accuracy: 0.318\n",
      "------------- epoch:  31\n",
      "Training loss: 0.143\n",
      "Validation loss: 0.690\n",
      "Validation accuracy: 0.378\n",
      "------------- epoch:  32\n",
      "Training loss: 0.086\n",
      "Validation loss: 0.659\n",
      "Validation accuracy: 0.379\n",
      "------------- epoch:  33\n",
      "Training loss: 0.078\n",
      "Validation loss: 0.739\n",
      "Validation accuracy: 0.376\n",
      "------------- epoch:  34\n",
      "Training loss: 0.066\n",
      "Validation loss: 0.778\n",
      "Validation accuracy: 0.408\n"
     ]
    }
   ],
   "source": [
    "normalized_weights = data.n_classes *data.weights /sum(data.weights)\n",
    "\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=.5, alpha=torch.tensor(normalized_weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 35, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Jeans                        89.3     100.0\n",
      "Trousers                     60.7     100.0\n",
      "Flats                        85.7     100.0\n",
      "Bra                          92.9      96.4\n",
      "Dresses                      28.0      68.0\n",
      "Earrings                    100.0     100.0\n",
      "Track Pants                  77.8     100.0\n",
      "Deodorant                     0.0       0.0\n",
      "Nail Polish                   0.0       0.0\n",
      "Sweatshirts                  67.9      92.9\n",
      "Clutches                     75.0     100.0\n",
      "Innerwear Vests               0.0     100.0\n",
      "Lipstick                      0.0       0.0\n",
      "Sweaters                     39.3      78.6\n",
      "Jackets                      44.0      88.0\n",
      "Ties                         95.2      95.2\n",
      "Caps                         85.2     100.0\n",
      "Kurtis                       40.0      92.0\n",
      "Tunics                       27.8     100.0\n",
      "Capris                       55.0      85.0\n",
      "Pendant                      47.6      90.5\n",
      "Necklace and Chains          91.7     100.0\n",
      "Dupatta                      50.0     100.0\n",
      "Scarves                      15.0      90.0\n",
      "Leggings                     30.8      69.2\n",
      "Night suits                  52.2      91.3\n",
      "Ring                        100.0     100.0\n",
      "Nightdress                   15.4      53.8\n",
      "Lip Gloss                     0.0       0.0\n",
      "Kajal and Eyeliner            0.0       0.0\n",
      "Stoles                       25.0     100.0\n",
      "Skirts                       75.0      93.8\n",
      "Duffel Bag                   66.7      85.7\n",
      "Free Gifts                    0.0      42.9\n",
      "Bangle                       21.4      64.3\n",
      "Face Moisturisers             0.0       0.0\n",
      "Kurta Sets                   84.6     100.0\n",
      "Cufflinks                   100.0     100.0\n",
      "Accessory Gift Set          100.0     100.0\n",
      "Foundation and Primer         0.0       0.0\n",
      "Sports Sandals               66.7     100.0\n",
      "Lounge Pants                 20.0      60.0\n",
      "Highlighter and Blush         0.0       0.0\n",
      "Laptop Bag                   42.9      85.7\n",
      "Bracelet                     76.9      92.3\n",
      "Jewellery Set               100.0     100.0\n",
      "Compact                       0.0       0.0\n",
      "Eyeshadow                     0.0       0.0\n",
      "Mobile Pouch                 16.7      66.7\n",
      "Fragrance Gift Set            0.0       0.0\n",
      "Lip Liner                     0.0       0.0\n",
      "Camisoles                    40.0      93.3\n",
      "Lounge Shorts                 0.0      14.3\n",
      "Messenger Bag                50.0      66.7\n",
      "Churidar                      0.0      50.0\n",
      "Tracksuits                   92.3     100.0\n",
      "Stockings                     0.0      10.0\n",
      "Mufflers                     55.6     100.0\n",
      "Bath Robe                     0.0       0.0\n",
      "Hair Colour                   0.0       0.0\n",
      "Shoe Accessories              0.0      18.2\n",
      "Gloves                      100.0     100.0\n",
      "Lip Care                      0.0       0.0\n",
      "Baby Dolls                    0.0       0.0\n",
      "Face Wash and Cleanser        0.0       0.0\n",
      "Waistcoat                   100.0     100.0\n",
      "Sunscreen                     0.0       0.0\n",
      "Basketballs                   0.0       0.0\n",
      "Swimwear                     25.0      50.0\n",
      "Concealer                     0.0       0.0\n",
      "Shapewear                     0.0       0.0\n",
      "Mascara                       0.0       0.0\n",
      "Rucksacks                   100.0     100.0\n",
      "Waist Pouch                   0.0       0.0\n",
      "Body Lotion                   0.0       0.0\n",
      "Mask and Peel                 0.0       0.0\n",
      "Tights                      100.0     100.0\n",
      "Footballs                   100.0     100.0\n",
      "Travel Accessory              0.0       0.0\n",
      "Lip Plumper                   0.0       0.0\n",
      "Eye Cream                     0.0       0.0\n",
      "Headband                      0.0       0.0\n",
      "Beauty Accessory              0.0       0.0\n",
      "Robe                          0.0       0.0\n",
      "Face Scrub and Exfoliator       0.0       0.0\n",
      "Nail Essentials               0.0       0.0\n",
      "Hat                           0.0       0.0\n",
      "Toner                         0.0       0.0\n",
      "Shrug                         0.0       0.0\n",
      "Makeup Remover                0.0       0.0\n",
      "Wristbands                    0.0       0.0\n",
      "Ties and Cufflinks            0.0       0.0\n",
      "Key chain                     0.0       0.0\n",
      "Umbrellas                     0.0       0.0\n",
      "Face Serum and Gel            0.0       0.0\n",
      "Shoe Laces                    0.0       0.0\n",
      "Mens Grooming Kit             0.0       0.0\n",
      "Body Wash and Scrub           0.0       0.0\n",
      "===========================================\n",
      "Average                      30.9      45.8\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_1537/model_epoch_34.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare this to not finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/fashion-dataset/styles_quoted.csv',\n",
    "                                '../data/fashion-dataset/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_weights = data.n_classes *data.weights /sum(data.weights)\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=.5, alpha=torch.tensor(normalized_weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.900\n",
      "Validation loss: 17.175\n",
      "Validation accuracy: 0.010\n",
      "------------- epoch:  1\n",
      "Training loss: 0.912\n",
      "Validation loss: 1.157\n",
      "Validation accuracy: 0.003\n",
      "------------- epoch:  2\n",
      "Training loss: 0.826\n",
      "Validation loss: 0.951\n",
      "Validation accuracy: 0.050\n",
      "------------- epoch:  3\n",
      "Training loss: 0.788\n",
      "Validation loss: 0.937\n",
      "Validation accuracy: 0.005\n",
      "------------- epoch:  4\n",
      "Training loss: 0.756\n",
      "Validation loss: 0.939\n",
      "Validation accuracy: 0.005\n",
      "------------- epoch:  5\n",
      "Training loss: 0.743\n",
      "Validation loss: 0.942\n",
      "Validation accuracy: 0.045\n",
      "------------- epoch:  6\n",
      "Training loss: 0.727\n",
      "Validation loss: 1.918\n",
      "Validation accuracy: 0.036\n",
      "------------- epoch:  7\n",
      "Training loss: 0.692\n",
      "Validation loss: 0.878\n",
      "Validation accuracy: 0.045\n",
      "------------- epoch:  8\n",
      "Training loss: 0.628\n",
      "Validation loss: 0.829\n",
      "Validation accuracy: 0.109\n",
      "------------- epoch:  9\n",
      "Training loss: 0.615\n",
      "Validation loss: 0.883\n",
      "Validation accuracy: 0.087\n",
      "------------- epoch:  10\n",
      "Training loss: 0.577\n",
      "Validation loss: 0.946\n",
      "Validation accuracy: 0.037\n",
      "------------- epoch:  11\n",
      "Training loss: 0.547\n",
      "Validation loss: 1.091\n",
      "Validation accuracy: 0.062\n",
      "------------- epoch:  12\n",
      "Training loss: 0.522\n",
      "Validation loss: 0.880\n",
      "Validation accuracy: 0.116\n",
      "------------- epoch:  13\n",
      "Training loss: 0.493\n",
      "Validation loss: 0.921\n",
      "Validation accuracy: 0.080\n",
      "------------- epoch:  14\n",
      "Training loss: 0.490\n",
      "Validation loss: 0.880\n",
      "Validation accuracy: 0.118\n",
      "------------- epoch:  15\n",
      "Training loss: 0.472\n",
      "Validation loss: 0.863\n",
      "Validation accuracy: 0.103\n",
      "------------- epoch:  16\n",
      "Training loss: 0.442\n",
      "Validation loss: 1.252\n",
      "Validation accuracy: 0.076\n",
      "------------- epoch:  17\n",
      "Training loss: 0.430\n",
      "Validation loss: 0.850\n",
      "Validation accuracy: 0.121\n",
      "------------- epoch:  18\n",
      "Training loss: 0.418\n",
      "Validation loss: 1.120\n",
      "Validation accuracy: 0.085\n",
      "------------- epoch:  19\n",
      "Training loss: 0.388\n",
      "Validation loss: 0.778\n",
      "Validation accuracy: 0.189\n",
      "------------- epoch:  20\n",
      "Training loss: 0.368\n",
      "Validation loss: 0.827\n",
      "Validation accuracy: 0.152\n",
      "------------- epoch:  21\n",
      "Training loss: 0.347\n",
      "Validation loss: 1.057\n",
      "Validation accuracy: 0.099\n",
      "------------- epoch:  22\n",
      "Training loss: 0.364\n",
      "Validation loss: 0.758\n",
      "Validation accuracy: 0.185\n",
      "------------- epoch:  23\n",
      "Training loss: 0.348\n",
      "Validation loss: 0.839\n",
      "Validation accuracy: 0.132\n",
      "------------- epoch:  24\n",
      "Training loss: 0.326\n",
      "Validation loss: 0.862\n",
      "Validation accuracy: 0.206\n",
      "------------- epoch:  25\n",
      "Training loss: 0.318\n",
      "Validation loss: 0.801\n",
      "Validation accuracy: 0.235\n",
      "------------- epoch:  26\n",
      "Training loss: 0.296\n",
      "Validation loss: 0.727\n",
      "Validation accuracy: 0.216\n",
      "------------- epoch:  27\n",
      "Training loss: 0.291\n",
      "Validation loss: 1.235\n",
      "Validation accuracy: 0.092\n",
      "------------- epoch:  28\n",
      "Training loss: 0.305\n",
      "Validation loss: 1.107\n",
      "Validation accuracy: 0.099\n",
      "------------- epoch:  29\n",
      "Training loss: 0.265\n",
      "Validation loss: 0.821\n",
      "Validation accuracy: 0.237\n",
      "------------- epoch:  30\n",
      "Training loss: 0.254\n",
      "Validation loss: 1.171\n",
      "Validation accuracy: 0.118\n",
      "------------- epoch:  31\n",
      "Training loss: 0.232\n",
      "Validation loss: 0.891\n",
      "Validation accuracy: 0.169\n",
      "------------- epoch:  32\n",
      "Training loss: 0.239\n",
      "Validation loss: 1.846\n",
      "Validation accuracy: 0.045\n",
      "------------- epoch:  33\n",
      "Training loss: 0.234\n",
      "Validation loss: 1.205\n",
      "Validation accuracy: 0.111\n",
      "------------- epoch:  34\n",
      "Training loss: 0.239\n",
      "Validation loss: 0.752\n",
      "Validation accuracy: 0.276\n"
     ]
    }
   ],
   "source": [
    "fewshot.trainer.run_training(model, 35, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Jeans                        64.3      92.9\n",
      "Trousers                     78.6      96.4\n",
      "Flats                        53.6      96.4\n",
      "Bra                          57.1      96.4\n",
      "Dresses                      36.0      64.0\n",
      "Earrings                     61.1     100.0\n",
      "Track Pants                  59.3      88.9\n",
      "Deodorant                     0.0       0.0\n",
      "Nail Polish                   0.0       0.0\n",
      "Sweatshirts                  25.0      89.3\n",
      "Clutches                     75.0      83.3\n",
      "Innerwear Vests               0.0       0.0\n",
      "Lipstick                      0.0       0.0\n",
      "Sweaters                     21.4      71.4\n",
      "Jackets                      12.0      68.0\n",
      "Ties                         90.5      95.2\n",
      "Caps                         59.3      81.5\n",
      "Kurtis                        4.0      80.0\n",
      "Tunics                       33.3      88.9\n",
      "Capris                       10.0      70.0\n",
      "Pendant                      47.6     100.0\n",
      "Necklace and Chains          58.3      91.7\n",
      "Dupatta                       0.0      50.0\n",
      "Scarves                      25.0      85.0\n",
      "Leggings                     30.8      61.5\n",
      "Night suits                  47.8      87.0\n",
      "Ring                         53.8     100.0\n",
      "Nightdress                    0.0      50.0\n",
      "Lip Gloss                     0.0       0.0\n",
      "Kajal and Eyeliner            0.0       0.0\n",
      "Stoles                        0.0      50.0\n",
      "Skirts                       12.5      68.8\n",
      "Duffel Bag                   33.3      57.1\n",
      "Free Gifts                    0.0      28.6\n",
      "Bangle                        0.0      57.1\n",
      "Face Moisturisers             0.0       0.0\n",
      "Kurta Sets                   92.3     100.0\n",
      "Cufflinks                    18.2     100.0\n",
      "Accessory Gift Set           55.0     100.0\n",
      "Foundation and Primer         0.0       0.0\n",
      "Sports Sandals               16.7      91.7\n",
      "Lounge Pants                  0.0      30.0\n",
      "Highlighter and Blush         0.0       0.0\n",
      "Laptop Bag                    0.0      71.4\n",
      "Bracelet                     61.5      92.3\n",
      "Jewellery Set                77.8     100.0\n",
      "Compact                       0.0       0.0\n",
      "Eyeshadow                     0.0       0.0\n",
      "Mobile Pouch                  8.3      16.7\n",
      "Fragrance Gift Set            0.0       0.0\n",
      "Lip Liner                     0.0       0.0\n",
      "Camisoles                    40.0      93.3\n",
      "Lounge Shorts                 0.0      57.1\n",
      "Messenger Bag                 0.0      66.7\n",
      "Churidar                      0.0      50.0\n",
      "Tracksuits                   53.8     100.0\n",
      "Stockings                     0.0      70.0\n",
      "Mufflers                     11.1      66.7\n",
      "Bath Robe                     0.0       0.0\n",
      "Hair Colour                   0.0       0.0\n",
      "Shoe Accessories              9.1      27.3\n",
      "Gloves                       50.0      50.0\n",
      "Lip Care                      0.0       0.0\n",
      "Baby Dolls                    0.0       0.0\n",
      "Face Wash and Cleanser        0.0       0.0\n",
      "Waistcoat                     0.0      20.0\n",
      "Sunscreen                     0.0       0.0\n",
      "Basketballs                   0.0       0.0\n",
      "Swimwear                     25.0      25.0\n",
      "Concealer                     0.0       0.0\n",
      "Shapewear                     0.0       0.0\n",
      "Mascara                       0.0       0.0\n",
      "Rucksacks                    40.0      40.0\n",
      "Waist Pouch                   0.0       0.0\n",
      "Body Lotion                   0.0       0.0\n",
      "Mask and Peel                 0.0       0.0\n",
      "Tights                        0.0       0.0\n",
      "Footballs                   100.0     100.0\n",
      "Travel Accessory              0.0       0.0\n",
      "Lip Plumper                   0.0       0.0\n",
      "Eye Cream                     0.0       0.0\n",
      "Headband                      0.0       0.0\n",
      "Beauty Accessory              0.0       0.0\n",
      "Robe                          0.0       0.0\n",
      "Face Scrub and Exfoliator       0.0       0.0\n",
      "Nail Essentials               0.0       0.0\n",
      "Hat                           0.0       0.0\n",
      "Toner                         0.0       0.0\n",
      "Shrug                         0.0       0.0\n",
      "Makeup Remover                0.0       0.0\n",
      "Wristbands                    0.0       0.0\n",
      "Ties and Cufflinks            0.0       0.0\n",
      "Key chain                     0.0     100.0\n",
      "Umbrellas                     0.0       0.0\n",
      "Face Serum and Gel            0.0       0.0\n",
      "Shoe Laces                    0.0       0.0\n",
      "Mens Grooming Kit             0.0       0.0\n",
      "Body Wash and Scrub           0.0       0.0\n",
      "===========================================\n",
      "Average                      17.4      39.0\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun10_1108/model_epoch_34.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>usage</th>\n",
       "      <th>productDisplayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Peter England Men Party Blue Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>51832</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Innerwear</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Beige</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Bwitch Beige Full-Coverage Bra BW335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>56019</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Lips</td>\n",
       "      <td>Lipstick</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Colorbar Soft Touch Show Stopper Copper Lipsti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>59051</td>\n",
       "      <td>Women</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Flats</td>\n",
       "      <td>Black</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Carlton London Women Black &amp; Gold Toned Flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2886</td>\n",
       "      <td>Women</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Flats</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Catwalk Women Leather Brown Flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8580</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Waistcoat</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Scullers Men  Grey Waistcoat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>59607</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Saree</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Ethnic</td>\n",
       "      <td>FNF Pink &amp; Grey Wedding Collection Sari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>23876</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Sweatshirts</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>ADIDAS Men Blue Sweatshirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>17885</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Innerwear</td>\n",
       "      <td>Innerwear Vests</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Levis Men Comfort Style Grey Innerwear Vest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>48781</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Jewellery</td>\n",
       "      <td>Pendant</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Lucera Women Silver Pendant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>25947</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Scarves</td>\n",
       "      <td>Scarves</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Femella Women Brown Scarf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>28456</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Skirts</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Urban Yoga Women Blue Skirt With Leggings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>39140</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Apparel Set</td>\n",
       "      <td>Kurta Sets</td>\n",
       "      <td>Black</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Ethnic</td>\n",
       "      <td>Aneri Women Black &amp; Maroon Salwar Suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>20851</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Clutches</td>\n",
       "      <td>Red</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Spice Art Women Ribbon Embroidery Red Clutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>47530</td>\n",
       "      <td>Women</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Flats</td>\n",
       "      <td>Copper</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Portia Women Copper-Toned &amp; Brown Sandals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>48578</td>\n",
       "      <td>Men</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Jewellery</td>\n",
       "      <td>Bracelet</td>\n",
       "      <td>Steel</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Revv Men Steel Bracelet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>18208</td>\n",
       "      <td>Men</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Headwear</td>\n",
       "      <td>Caps</td>\n",
       "      <td>White</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Manchester United Men Solid White Cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>25382</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Innerwear</td>\n",
       "      <td>Innerwear Vests</td>\n",
       "      <td>White</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Levis Men White Innerwear Vest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>10257</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Formal</td>\n",
       "      <td>John Miller Men Solid Type Black Trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>11385</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Sweatshirts</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>United Colors Of Benetton Women Light Winter B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>53130</td>\n",
       "      <td>Women</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Flats</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Catwalk Women Brown Sandals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>26735</td>\n",
       "      <td>Men</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Deodorant</td>\n",
       "      <td>Black</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Reebok Men Pack of 2 Pirates of the Caribbean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>56026</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Lips</td>\n",
       "      <td>Lipstick</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Colorbar Soft Touch Mousse Lipstick 025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>32563</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>ONLY Women directoire blue Trousers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>58980</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Deodorant</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Colour me Women Flowers Deo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>52486</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Innerwear</td>\n",
       "      <td>Camisoles</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Red Rose Maroon Camisole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>53554</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Innerwear</td>\n",
       "      <td>Boxers</td>\n",
       "      <td>Multi</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Probase Multicoloured Printed Boxers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>7193</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Jealous 21 Women Black Jegging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>51031</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Innerwear</td>\n",
       "      <td>Bra</td>\n",
       "      <td>White</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Enamor White Bra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>55491</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Lips</td>\n",
       "      <td>Lip Gloss</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Revlon Gold Dust Poussiere Doree Colorburst Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44283</th>\n",
       "      <td>55277</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Makeup</td>\n",
       "      <td>Highlighter and Blush</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Lakme Women Pure Rouge Rose Crush Blusher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44284</th>\n",
       "      <td>26785</td>\n",
       "      <td>Men</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Deodorant</td>\n",
       "      <td>Red</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Reebok Men Pack of 3 Deos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44285</th>\n",
       "      <td>31732</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Blazers</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Formal</td>\n",
       "      <td>Reid &amp; Taylor Men Brown Blazer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44309</th>\n",
       "      <td>43776</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Jewellery</td>\n",
       "      <td>Earrings</td>\n",
       "      <td>White</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Ethnic</td>\n",
       "      <td>Royal Diadem White &amp; Green Earrings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44318</th>\n",
       "      <td>31164</td>\n",
       "      <td>Boys</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Gini and Jony Boys Blue Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44319</th>\n",
       "      <td>55421</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Lips</td>\n",
       "      <td>Lipstick</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Revlon Moisture Stay Spice Lipstick 31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44320</th>\n",
       "      <td>27001</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Jealous 21 Women Washed Light Blue Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44326</th>\n",
       "      <td>16746</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Clutches</td>\n",
       "      <td>Cream</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Spice Art Women Zircons Cream Clutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44330</th>\n",
       "      <td>46036</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Jewellery</td>\n",
       "      <td>Jewellery Set</td>\n",
       "      <td>Gold</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Estelle Women Gold Jewellery Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44331</th>\n",
       "      <td>48990</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Jewellery</td>\n",
       "      <td>Ring</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Lucera Women Silver Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44336</th>\n",
       "      <td>20224</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Wrangler Women Felt Purple Sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44340</th>\n",
       "      <td>4594</td>\n",
       "      <td>Unisex</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Rucksacks</td>\n",
       "      <td>Red</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Wildcraft Unisex Red &amp; Grey Rucksack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44355</th>\n",
       "      <td>24442</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Innerwear</td>\n",
       "      <td>Innerwear Vests</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Facit Men Grey Printed Innerwear Vest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44357</th>\n",
       "      <td>32527</td>\n",
       "      <td>Men</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Deodorant</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Tonino Lamborghini Men Forza Deo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44358</th>\n",
       "      <td>25590</td>\n",
       "      <td>Women</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Apparel Set</td>\n",
       "      <td>Kurta Sets</td>\n",
       "      <td>Beige</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Ethnic</td>\n",
       "      <td>Vishudh Women Beige &amp; Green Printed Churidar K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44359</th>\n",
       "      <td>56062</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Lips</td>\n",
       "      <td>Lip Gloss</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Colorbar Extra Durable Gossip Lip Color 005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44361</th>\n",
       "      <td>26315</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Charcoal</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Proline Men Charcoal Grey Track Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44365</th>\n",
       "      <td>6839</td>\n",
       "      <td>Unisex</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Shoe Accessories</td>\n",
       "      <td>Shoe Accessories</td>\n",
       "      <td>Black</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Timberland Unisex Waximum Shoe Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44372</th>\n",
       "      <td>47322</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Mobile Pouch</td>\n",
       "      <td>Tan</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Baggit Women Brown Chakde Lips Mobile Pouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44377</th>\n",
       "      <td>18628</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Knitted Chocolate Brown Sweaters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44381</th>\n",
       "      <td>2697</td>\n",
       "      <td>Girls</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Disney Kids Girl's Blue Pooh Kidswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44387</th>\n",
       "      <td>23455</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Deni Yo Men Blue Washed Slim Fit Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44388</th>\n",
       "      <td>48964</td>\n",
       "      <td>Men</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Jewellery</td>\n",
       "      <td>Ring</td>\n",
       "      <td>Steel</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Revv Men Steel Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44390</th>\n",
       "      <td>37267</td>\n",
       "      <td>Girls</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Red</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>United Colors of Benetton Girls Red Printed Dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44394</th>\n",
       "      <td>10445</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Flying Machine Men Midrise Blue Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44400</th>\n",
       "      <td>54163</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Jewellery</td>\n",
       "      <td>Necklace and Chains</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Femella Silver Necklace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44418</th>\n",
       "      <td>56634</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face Wash and Cleanser</td>\n",
       "      <td>Black</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Olay Women Total Effects 7 in 1 Foaming Cleanser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44424</th>\n",
       "      <td>15761</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Innerwear</td>\n",
       "      <td>Innerwear Vests</td>\n",
       "      <td>Green</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Facit Men Hunk Green Innerwear Vest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44430</th>\n",
       "      <td>56406</td>\n",
       "      <td>Women</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Flats</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Rocia Women Maroon &amp; Black Sandals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44438</th>\n",
       "      <td>55283</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Makeup</td>\n",
       "      <td>Highlighter and Blush</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Lakme Absolute Cheek Chromatic Day Blushes Blu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7337 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender masterCategory       subCategory             articleType  \\\n",
       "1      39386     Men        Apparel        Bottomwear                   Jeans   \n",
       "18     51832   Women        Apparel         Innerwear                     Bra   \n",
       "28     56019   Women  Personal Care              Lips                Lipstick   \n",
       "34     59051   Women       Footwear             Shoes                   Flats   \n",
       "41      2886   Women       Footwear             Shoes                   Flats   \n",
       "44      8580     Men        Apparel           Topwear               Waistcoat   \n",
       "60     59607   Women        Apparel             Saree                  Sarees   \n",
       "74     23876     Men        Apparel           Topwear             Sweatshirts   \n",
       "83     17885     Men        Apparel         Innerwear         Innerwear Vests   \n",
       "85     48781   Women    Accessories         Jewellery                 Pendant   \n",
       "91     25947   Women    Accessories           Scarves                 Scarves   \n",
       "100    28456   Women        Apparel        Bottomwear                  Skirts   \n",
       "134    39140   Women        Apparel       Apparel Set              Kurta Sets   \n",
       "135    20851   Women    Accessories              Bags                Clutches   \n",
       "143    47530   Women       Footwear             Shoes                   Flats   \n",
       "150    48578     Men    Accessories         Jewellery                Bracelet   \n",
       "152    18208     Men    Accessories          Headwear                    Caps   \n",
       "157    25382     Men        Apparel         Innerwear         Innerwear Vests   \n",
       "166    10257     Men        Apparel        Bottomwear                Trousers   \n",
       "169    11385   Women        Apparel           Topwear             Sweatshirts   \n",
       "170    53130   Women       Footwear             Shoes                   Flats   \n",
       "183    26735     Men  Personal Care         Fragrance               Deodorant   \n",
       "185    56026   Women  Personal Care              Lips                Lipstick   \n",
       "187    32563   Women        Apparel        Bottomwear                Trousers   \n",
       "188    58980   Women  Personal Care         Fragrance               Deodorant   \n",
       "195    52486   Women        Apparel         Innerwear               Camisoles   \n",
       "196    53554     Men        Apparel         Innerwear                  Boxers   \n",
       "204     7193   Women        Apparel        Bottomwear                   Jeans   \n",
       "217    51031   Women        Apparel         Innerwear                     Bra   \n",
       "220    55491   Women  Personal Care              Lips               Lip Gloss   \n",
       "...      ...     ...            ...               ...                     ...   \n",
       "44283  55277   Women  Personal Care            Makeup   Highlighter and Blush   \n",
       "44284  26785     Men  Personal Care         Fragrance               Deodorant   \n",
       "44285  31732     Men        Apparel           Topwear                 Blazers   \n",
       "44309  43776   Women    Accessories         Jewellery                Earrings   \n",
       "44318  31164    Boys        Apparel        Bottomwear                   Jeans   \n",
       "44319  55421   Women  Personal Care              Lips                Lipstick   \n",
       "44320  27001   Women        Apparel        Bottomwear                   Jeans   \n",
       "44326  16746   Women    Accessories              Bags                Clutches   \n",
       "44330  46036   Women    Accessories         Jewellery           Jewellery Set   \n",
       "44331  48990   Women    Accessories         Jewellery                    Ring   \n",
       "44336  20224   Women        Apparel           Topwear                Sweaters   \n",
       "44340   4594  Unisex    Accessories              Bags               Rucksacks   \n",
       "44355  24442     Men        Apparel         Innerwear         Innerwear Vests   \n",
       "44357  32527     Men  Personal Care         Fragrance               Deodorant   \n",
       "44358  25590   Women        Apparel       Apparel Set              Kurta Sets   \n",
       "44359  56062   Women  Personal Care              Lips               Lip Gloss   \n",
       "44361  26315     Men        Apparel        Bottomwear             Track Pants   \n",
       "44365   6839  Unisex    Accessories  Shoe Accessories        Shoe Accessories   \n",
       "44372  47322   Women    Accessories              Bags            Mobile Pouch   \n",
       "44377  18628     Men        Apparel           Topwear                Sweaters   \n",
       "44381   2697   Girls        Apparel             Dress                 Dresses   \n",
       "44387  23455     Men        Apparel        Bottomwear                   Jeans   \n",
       "44388  48964     Men    Accessories         Jewellery                    Ring   \n",
       "44390  37267   Girls        Apparel             Dress                 Dresses   \n",
       "44394  10445     Men        Apparel        Bottomwear                   Jeans   \n",
       "44400  54163   Women    Accessories         Jewellery     Necklace and Chains   \n",
       "44418  56634   Women  Personal Care         Skin Care  Face Wash and Cleanser   \n",
       "44424  15761     Men        Apparel         Innerwear         Innerwear Vests   \n",
       "44430  56406   Women       Footwear             Shoes                   Flats   \n",
       "44438  55283   Women  Personal Care            Makeup   Highlighter and Blush   \n",
       "\n",
       "      baseColour  season    year   usage  \\\n",
       "1           Blue  Summer  2012.0  Casual   \n",
       "18         Beige  Summer  2016.0  Casual   \n",
       "28         Brown  Spring  2017.0  Casual   \n",
       "34         Black  Winter  2012.0  Casual   \n",
       "41         Brown  Winter  2015.0  Casual   \n",
       "44          Grey    Fall  2011.0  Casual   \n",
       "60          Grey    Fall  2012.0  Ethnic   \n",
       "74          Blue    Fall  2011.0  Casual   \n",
       "83          Grey  Summer  2016.0  Casual   \n",
       "85        Silver  Summer  2012.0  Casual   \n",
       "91         Brown  Summer  2012.0  Casual   \n",
       "100         Blue  Summer  2012.0  Sports   \n",
       "134        Black  Summer  2012.0  Ethnic   \n",
       "135          Red  Winter  2015.0  Casual   \n",
       "143       Copper  Winter  2012.0  Casual   \n",
       "150        Steel  Summer  2012.0  Casual   \n",
       "152        White    Fall  2011.0  Casual   \n",
       "157        White  Summer  2016.0  Casual   \n",
       "166        Black    Fall  2011.0  Formal   \n",
       "169        Black    Fall  2011.0  Casual   \n",
       "170        Brown  Winter  2015.0  Casual   \n",
       "183        Black  Spring  2017.0  Casual   \n",
       "185        Brown  Spring  2017.0  Casual   \n",
       "187         Blue  Summer  2012.0  Casual   \n",
       "188         Pink  Spring  2017.0  Casual   \n",
       "195       Maroon  Winter  2015.0  Casual   \n",
       "196        Multi  Summer  2016.0  Casual   \n",
       "204        Black    Fall  2011.0  Casual   \n",
       "217        White  Summer  2017.0  Casual   \n",
       "220        Brown  Spring  2017.0  Casual   \n",
       "...          ...     ...     ...     ...   \n",
       "44283       Pink  Spring  2017.0  Casual   \n",
       "44284        Red  Spring  2017.0  Casual   \n",
       "44285      Brown  Summer  2012.0  Formal   \n",
       "44309      White  Summer  2012.0  Ethnic   \n",
       "44318       Blue  Summer  2012.0  Casual   \n",
       "44319      Brown  Spring  2017.0  Casual   \n",
       "44320       Blue  Summer  2012.0  Casual   \n",
       "44326      Cream  Winter  2015.0  Casual   \n",
       "44330       Gold  Winter  2016.0  Casual   \n",
       "44331     Silver  Summer  2012.0  Casual   \n",
       "44336     Purple    Fall  2011.0  Casual   \n",
       "44340        Red  Winter  2015.0  Casual   \n",
       "44355       Grey  Summer  2016.0  Casual   \n",
       "44357       Blue  Spring  2017.0  Casual   \n",
       "44358      Beige    Fall  2011.0  Ethnic   \n",
       "44359       Pink  Spring  2017.0  Casual   \n",
       "44361   Charcoal    Fall  2013.0  Sports   \n",
       "44365      Black  Winter  2015.0     NaN   \n",
       "44372        Tan    Fall  2012.0  Casual   \n",
       "44377      Brown    Fall  2011.0  Casual   \n",
       "44381       Blue  Summer  2011.0  Casual   \n",
       "44387       Blue  Summer  2012.0  Casual   \n",
       "44388      Steel  Summer  2012.0  Casual   \n",
       "44390        Red  Summer  2012.0  Casual   \n",
       "44394       Blue    Fall  2011.0  Casual   \n",
       "44400     Silver    Fall  2012.0  Casual   \n",
       "44418      Black  Spring  2017.0  Casual   \n",
       "44424      Green  Summer  2016.0  Casual   \n",
       "44430     Maroon  Winter  2012.0  Casual   \n",
       "44438       Pink  Spring  2017.0  Casual   \n",
       "\n",
       "                                      productDisplayName  \n",
       "1                     Peter England Men Party Blue Jeans  \n",
       "18                  Bwitch Beige Full-Coverage Bra BW335  \n",
       "28     Colorbar Soft Touch Show Stopper Copper Lipsti...  \n",
       "34         Carlton London Women Black & Gold Toned Flats  \n",
       "41                     Catwalk Women Leather Brown Flats  \n",
       "44                          Scullers Men  Grey Waistcoat  \n",
       "60               FNF Pink & Grey Wedding Collection Sari  \n",
       "74                            ADIDAS Men Blue Sweatshirt  \n",
       "83           Levis Men Comfort Style Grey Innerwear Vest  \n",
       "85                           Lucera Women Silver Pendant  \n",
       "91                             Femella Women Brown Scarf  \n",
       "100            Urban Yoga Women Blue Skirt With Leggings  \n",
       "134               Aneri Women Black & Maroon Salwar Suit  \n",
       "135         Spice Art Women Ribbon Embroidery Red Clutch  \n",
       "143            Portia Women Copper-Toned & Brown Sandals  \n",
       "150                              Revv Men Steel Bracelet  \n",
       "152                Manchester United Men Solid White Cap  \n",
       "157                       Levis Men White Innerwear Vest  \n",
       "166            John Miller Men Solid Type Black Trousers  \n",
       "169    United Colors Of Benetton Women Light Winter B...  \n",
       "170                          Catwalk Women Brown Sandals  \n",
       "183    Reebok Men Pack of 2 Pirates of the Caribbean ...  \n",
       "185              Colorbar Soft Touch Mousse Lipstick 025  \n",
       "187                  ONLY Women directoire blue Trousers  \n",
       "188                          Colour me Women Flowers Deo  \n",
       "195                             Red Rose Maroon Camisole  \n",
       "196                 Probase Multicoloured Printed Boxers  \n",
       "204                       Jealous 21 Women Black Jegging  \n",
       "217                                     Enamor White Bra  \n",
       "220    Revlon Gold Dust Poussiere Doree Colorburst Li...  \n",
       "...                                                  ...  \n",
       "44283          Lakme Women Pure Rouge Rose Crush Blusher  \n",
       "44284                          Reebok Men Pack of 3 Deos  \n",
       "44285                     Reid & Taylor Men Brown Blazer  \n",
       "44309                Royal Diadem White & Green Earrings  \n",
       "44318                      Gini and Jony Boys Blue Jeans  \n",
       "44319             Revlon Moisture Stay Spice Lipstick 31  \n",
       "44320           Jealous 21 Women Washed Light Blue Jeans  \n",
       "44326               Spice Art Women Zircons Cream Clutch  \n",
       "44330                   Estelle Women Gold Jewellery Set  \n",
       "44331                           Lucera Women Silver Ring  \n",
       "44336                 Wrangler Women Felt Purple Sweater  \n",
       "44340               Wildcraft Unisex Red & Grey Rucksack  \n",
       "44355              Facit Men Grey Printed Innerwear Vest  \n",
       "44357                   Tonino Lamborghini Men Forza Deo  \n",
       "44358  Vishudh Women Beige & Green Printed Churidar K...  \n",
       "44359        Colorbar Extra Durable Gossip Lip Color 005  \n",
       "44361              Proline Men Charcoal Grey Track Pants  \n",
       "44365         Timberland Unisex Waximum Shoe Accessories  \n",
       "44372        Baggit Women Brown Chakde Lips Mobile Pouch  \n",
       "44377          Puma Men Knitted Chocolate Brown Sweaters  \n",
       "44381              Disney Kids Girl's Blue Pooh Kidswear  \n",
       "44387             Deni Yo Men Blue Washed Slim Fit Jeans  \n",
       "44388                                Revv Men Steel Ring  \n",
       "44390  United Colors of Benetton Girls Red Printed Dress  \n",
       "44394              Flying Machine Men Midrise Blue Jeans  \n",
       "44400                            Femella Silver Necklace  \n",
       "44418   Olay Women Total Effects 7 in 1 Foaming Cleanser  \n",
       "44424                Facit Men Hunk Green Innerwear Vest  \n",
       "44430                 Rocia Women Maroon & Black Sandals  \n",
       "44438  Lakme Absolute Cheek Chromatic Day Blushes Blu...  \n",
       "\n",
       "[7337 rows x 10 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_classes = np.random.choice(data.train_ds.label_data.articleType.unique(), size=20, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tunics', 'Bracelet', 'Mufflers', 'Rain Jacket', 'Night suits',\n",
       "       'Ipad', 'Suspenders', 'Sweaters', 'Skirts', 'Caps', 'Key chain',\n",
       "       'Stoles', 'Ring', 'Mobile Pouch', 'Clutches', 'Trolley Bag',\n",
       "       'Pendant', 'Track Pants', 'Salwar and Dupatta', 'Duffel Bag'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5,    7,   10,   15,   23,   27,   28,   31,   42,   48,   49,\n",
       "         55,   56,   58,   60,   78,   87,   89,   95,   96,  105,  112,\n",
       "        113,  114,  122,  127,  130,  132,  135,  137,  138,  147,  154,\n",
       "        155,  156,  162,  170,  173,  176,  182,  184,  189,  199,  201,\n",
       "        204,  207,  208,  211,  223,  227,  228,  232,  233,  235,  240,\n",
       "        248,  249,  252,  256,  258,  259,  261,  262,  264,  267,  268,\n",
       "        269,  271,  275,  284,  287,  294,  298,  300,  301,  304,  308,\n",
       "        313,  317,  319,  323,  326,  331,  332,  336,  337,  338,  341,\n",
       "        342,  345,  353,  361,  365,  366,  368,  373,  386,  391,  393,\n",
       "        398,  409,  413,  415,  424,  425,  426,  427,  431,  441,  444,\n",
       "        452,  457,  470,  482,  487,  491,  492,  501,  508,  509,  512,\n",
       "        513,  516,  522,  524,  530,  535,  537,  539,  540,  551,  556,\n",
       "        557,  561,  565,  571,  573,  578,  586,  591,  598,  601,  603,\n",
       "        617,  626,  627,  644,  645,  648,  649,  651,  652,  656,  660,\n",
       "        664,  670,  676,  688,  690,  691,  698,  699,  719,  722,  724,\n",
       "        730,  731,  732,  733,  748,  750,  754,  757,  762,  768,  776,\n",
       "        779,  780,  787,  788,  795,  803,  806,  807,  811,  814,  815,\n",
       "        816,  835,  840,  841,  842,  843,  849,  852,  856,  863,  880,\n",
       "        885,  891,  901,  903,  923,  929,  942,  950,  952,  964,  966,\n",
       "        973,  979,  983,  993, 1006, 1009, 1010, 1024, 1025, 1026, 1027,\n",
       "       1035, 1051, 1056, 1064, 1075, 1094, 1095, 1098, 1102, 1105, 1106,\n",
       "       1111, 1122, 1128, 1130, 1136, 1139, 1143, 1150, 1152, 1163, 1174,\n",
       "       1178, 1187, 1188, 1189, 1190, 1195, 1198, 1213, 1222, 1228, 1232,\n",
       "       1233, 1241, 1244, 1245, 1248, 1250, 1260, 1266, 1271, 1276, 1278,\n",
       "       1279, 1288, 1292, 1297, 1303, 1304, 1307, 1308, 1319, 1323, 1327,\n",
       "       1335, 1344, 1348, 1349, 1354, 1369, 1371, 1376, 1392, 1393, 1395,\n",
       "       1408, 1421, 1426, 1431, 1435, 1443, 1446, 1452, 1458, 1459, 1461,\n",
       "       1465, 1467, 1468, 1469, 1480, 1489, 1492, 1493, 1499, 1506, 1507,\n",
       "       1508, 1513, 1516, 1522, 1523, 1525, 1526, 1538, 1549, 1551, 1555,\n",
       "       1556, 1559, 1560, 1565, 1569, 1578, 1581, 1582, 1584, 1586, 1588,\n",
       "       1589, 1591, 1593, 1602, 1605, 1607, 1610, 1618, 1624, 1635, 1636,\n",
       "       1649, 1651, 1654, 1656, 1659, 1660, 1662, 1663, 1664, 1674, 1679,\n",
       "       1684, 1689, 1692, 1695, 1703, 1706, 1718, 1720, 1721, 1722, 1726,\n",
       "       1729, 1731, 1737, 1742, 1750, 1753, 1766, 1774, 1775, 1787, 1788,\n",
       "       1789, 1797, 1802, 1811, 1812, 1814, 1821, 1826, 1828, 1830, 1834,\n",
       "       1835, 1836, 1840, 1843, 1846, 1847, 1854, 1859, 1861, 1862, 1872,\n",
       "       1874, 1883, 1886, 1887, 1891, 1896, 1898, 1900, 1902, 1904, 1906,\n",
       "       1907, 1917, 1923, 1932, 1939, 1943, 1952, 1956, 1966, 1975, 1979,\n",
       "       1987, 1988, 1989, 2002, 2004, 2007, 2009, 2011, 2013, 2015, 2016,\n",
       "       2022, 2023, 2024, 2028, 2030, 2036, 2041, 2042, 2045, 2049, 2056,\n",
       "       2059, 2062, 2063, 2072, 2080, 2082, 2087, 2090, 2093, 2099, 2101,\n",
       "       2104, 2106, 2109, 2118, 2119, 2127, 2128, 2130, 2131, 2143, 2145,\n",
       "       2170, 2171, 2173, 2175, 2195, 2196, 2199, 2203, 2206, 2209, 2213,\n",
       "       2221, 2222, 2224, 2226, 2227, 2230, 2232, 2236, 2239, 2245, 2252,\n",
       "       2254, 2255, 2256, 2261, 2269, 2271, 2272, 2278, 2281, 2297, 2303,\n",
       "       2312, 2313, 2319, 2320, 2325, 2329, 2335, 2336, 2346, 2347, 2348,\n",
       "       2352, 2354, 2359, 2372, 2375, 2390, 2391, 2408, 2421, 2423, 2427,\n",
       "       2438, 2441, 2449, 2452, 2458, 2459, 2466, 2469, 2471, 2472, 2475,\n",
       "       2478, 2485, 2490, 2492, 2494, 2495, 2500, 2505, 2509, 2524, 2531,\n",
       "       2536, 2542, 2544, 2555, 2565, 2566, 2569, 2576, 2584, 2591, 2592,\n",
       "       2601, 2616, 2621, 2633, 2646, 2650, 2663, 2667, 2673, 2678, 2685,\n",
       "       2686, 2689, 2690, 2694, 2699, 2704, 2705, 2707, 2715, 2720, 2728,\n",
       "       2734, 2735, 2736, 2754, 2757, 2759, 2767, 2770, 2773, 2775, 2780,\n",
       "       2782, 2787, 2792, 2795, 2796, 2799, 2802, 2811, 2815, 2819, 2823,\n",
       "       2827, 2842, 2845, 2849, 2862, 2863, 2867, 2868, 2872, 2876, 2878,\n",
       "       2880, 2883, 2884, 2885, 2895, 2897, 2901, 2903, 2904, 2907, 2912,\n",
       "       2929, 2930, 2932, 2938, 2943, 2945, 2952, 2956, 2957, 2960, 2962,\n",
       "       2971, 2972, 2973, 2980, 2986, 2991, 3002, 3004, 3008, 3011, 3013,\n",
       "       3016, 3019, 3026, 3031, 3032, 3043, 3049, 3051, 3053, 3058, 3060,\n",
       "       3064, 3067, 3074, 3075, 3086, 3088, 3094, 3096, 3097, 3105, 3108,\n",
       "       3109, 3112, 3120, 3121, 3128, 3131, 3143, 3146, 3148, 3151, 3163,\n",
       "       3172, 3190, 3192, 3195, 3196, 3202, 3203, 3212, 3213, 3216, 3221,\n",
       "       3230, 3231, 3232, 3242, 3245, 3249, 3252, 3255, 3257, 3258, 3260,\n",
       "       3262, 3270, 3271, 3290, 3305, 3311, 3312, 3314, 3315, 3316, 3321,\n",
       "       3322, 3324, 3331, 3333, 3335, 3340, 3342, 3347, 3354, 3358, 3362,\n",
       "       3365, 3368, 3371, 3372, 3374, 3375, 3383, 3388, 3393, 3397, 3398,\n",
       "       3405, 3409, 3412, 3413, 3416, 3422, 3430, 3432, 3435, 3439, 3443,\n",
       "       3444, 3446, 3450, 3453, 3455, 3460, 3463, 3465, 3471, 3476, 3477,\n",
       "       3480, 3483, 3489, 3499, 3505, 3507, 3508, 3509, 3510, 3511, 3515,\n",
       "       3524, 3525, 3526, 3534, 3537, 3538, 3541, 3556, 3560, 3561, 3571,\n",
       "       3575, 3576, 3577, 3579, 3591, 3593, 3598, 3600, 3601, 3603, 3604,\n",
       "       3611, 3615, 3618, 3623, 3636, 3637, 3639, 3641, 3642, 3643, 3644,\n",
       "       3645, 3652, 3658, 3660, 3665, 3667, 3671, 3673, 3675, 3686, 3693,\n",
       "       3696, 3697, 3700, 3702, 3703, 3704, 3706, 3712, 3718, 3719, 3727,\n",
       "       3730, 3737, 3738, 3740, 3744, 3745, 3755, 3756, 3762, 3764, 3766])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds.label_data[data.train_ds.label_data.articleType.isin(episode_classes)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data.train_ds.label_data.articleType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sarees                 292\n",
       "Dresses                227\n",
       "Jeans                  221\n",
       "Flats                  201\n",
       "Earrings               192\n",
       "Innerwear Vests        186\n",
       "Trousers               177\n",
       "Clutches               139\n",
       "Ties                   115\n",
       "Trunk                  110\n",
       "Dupatta                100\n",
       "Track Pants             98\n",
       "Tunics                  96\n",
       "Bra                     92\n",
       "Caps                    84\n",
       "Necklace and Chains     81\n",
       "Capris                  79\n",
       "Leggings                76\n",
       "Kurtis                  75\n",
       "Stoles                  68\n",
       "Scarves                 59\n",
       "Jackets                 55\n",
       "Pendant                 55\n",
       "Free Gifts              51\n",
       "Skirts                  50\n",
       "Night suits             47\n",
       "Boxers                  41\n",
       "Bangle                  41\n",
       "Ring                    41\n",
       "Suspenders              40\n",
       "                      ... \n",
       "Rain Jacket              8\n",
       "Rompers                  8\n",
       "Waistcoat                8\n",
       "Shapewear                8\n",
       "Tracksuits               7\n",
       "Water Bottle             7\n",
       "Mufflers                 7\n",
       "Swimwear                 6\n",
       "Booties                  6\n",
       "Jumpsuit                 5\n",
       "Accessory Gift Set       5\n",
       "Tights                   5\n",
       "Footballs                5\n",
       "Shoe Accessories         4\n",
       "Camisoles                4\n",
       "Nehru Jackets            3\n",
       "Blazers                  3\n",
       "Lehenga Choli            2\n",
       "Shrug                    2\n",
       "Trolley Bag              2\n",
       "Rucksacks                2\n",
       "Travel Accessory         2\n",
       "Tablet Sleeve            2\n",
       "Salwar and Dupatta       2\n",
       "Lounge Tshirts           2\n",
       "Headband                 1\n",
       "Ipad                     1\n",
       "Robe                     1\n",
       "Hair Accessory           1\n",
       "Key chain                1\n",
       "Name: articleType, Length: 80, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
