{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import fewshot.data\n",
    "import fewshot.trainer\n",
    "import fewshot.focal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and results on large dataset\n",
    "\n",
    "This notebook contains the training and results for the fashion dataset, as well as all the different \"tricks\" to improve classification accuracy on the rare classes.\n",
    "\n",
    "NB: I did a little bit of hyperparameter optimization \"offline\" - mostly around the learning rate, gamma for the focal loss, which number of epochs was appropriate, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot.data.fix_quotes('../data/fashion-dataset/styles.csv', '../data/fashion-dataset/styles_quoted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/small/styles_quoted.csv',\n",
    "                                '../data/small/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "## replacing the last layer with the dense layer we need\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which loss performs better on top20?\n",
    "### Plain Cross-Entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n",
      "Training loss: 0.732\n",
      "Validation loss: 1.064\n",
      "Validation accuracy: 0.737\n",
      "------------- epoch:  1\n",
      "Training loss: 0.450\n",
      "Validation loss: 0.975\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  2\n",
      "Training loss: 0.386\n",
      "Validation loss: 0.976\n",
      "Validation accuracy: 0.795\n",
      "------------- epoch:  3\n",
      "Training loss: 0.349\n",
      "Validation loss: 1.057\n",
      "Validation accuracy: 0.816\n",
      "------------- epoch:  4\n",
      "Training loss: 0.320\n",
      "Validation loss: 0.821\n",
      "Validation accuracy: 0.817\n",
      "------------- epoch:  5\n",
      "Training loss: 0.281\n",
      "Validation loss: 1.153\n",
      "Validation accuracy: 0.792\n",
      "------------- epoch:  6\n",
      "Training loss: 0.284\n",
      "Validation loss: 0.853\n",
      "Validation accuracy: 0.840\n",
      "------------- epoch:  7\n",
      "Training loss: 0.259\n",
      "Validation loss: 0.959\n",
      "Validation accuracy: 0.837\n",
      "------------- epoch:  8\n",
      "Training loss: 0.241\n",
      "Validation loss: 0.900\n",
      "Validation accuracy: 0.842\n",
      "------------- epoch:  9\n",
      "Training loss: 0.243\n",
      "Validation loss: 0.930\n",
      "Validation accuracy: 0.832\n",
      "------------- epoch:  10\n",
      "Training loss: 0.225\n",
      "Validation loss: 1.335\n",
      "Validation accuracy: 0.739\n",
      "------------- epoch:  11\n",
      "Training loss: 0.221\n",
      "Validation loss: 1.120\n",
      "Validation accuracy: 0.825\n",
      "------------- epoch:  12\n",
      "Training loss: 0.209\n",
      "Validation loss: 1.035\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  13\n",
      "Training loss: 0.208\n",
      "Validation loss: 0.962\n",
      "Validation accuracy: 0.847\n",
      "------------- epoch:  14\n",
      "Training loss: 0.205\n",
      "Validation loss: 1.031\n",
      "Validation accuracy: 0.839\n",
      "------------- epoch:  15\n",
      "Training loss: 0.182\n",
      "Validation loss: 0.947\n",
      "Validation accuracy: 0.857\n",
      "------------- epoch:  16\n",
      "Training loss: 0.187\n",
      "Validation loss: 0.985\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  17\n",
      "Training loss: 0.181\n",
      "Validation loss: 0.904\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  18\n",
      "Training loss: 0.169\n",
      "Validation loss: 0.982\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  19\n",
      "Training loss: 0.166\n",
      "Validation loss: 1.040\n",
      "Validation accuracy: 0.846\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      89.1      99.2\n",
      "Shirts                       98.3     100.0\n",
      "Casual Shoes                 86.6      98.3\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 73.9     100.0\n",
      "Kurtas                       94.9      99.1\n",
      "Tops                         66.7     100.0\n",
      "Handbags                     95.0      99.2\n",
      "Heels                        89.7      99.1\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      95.7      99.1\n",
      "Flip Flops                   87.6      96.5\n",
      "Sandals                      78.4     100.0\n",
      "Briefs                       95.5     100.0\n",
      "Belts                        97.3      99.1\n",
      "Backpacks                    84.2      99.1\n",
      "Socks                        77.3      93.8\n",
      "Formal Shoes                 77.8      99.1\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      84.4      94.1\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0014/model_epoch_18.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.463\n",
      "Validation loss: 0.766\n",
      "Validation accuracy: 0.690\n",
      "------------- epoch:  1\n",
      "Training loss: 0.274\n",
      "Validation loss: 0.628\n",
      "Validation accuracy: 0.772\n",
      "------------- epoch:  2\n",
      "Training loss: 0.209\n",
      "Validation loss: 0.604\n",
      "Validation accuracy: 0.779\n",
      "------------- epoch:  3\n",
      "Training loss: 0.173\n",
      "Validation loss: 0.640\n",
      "Validation accuracy: 0.788\n",
      "------------- epoch:  4\n",
      "Training loss: 0.159\n",
      "Validation loss: 0.620\n",
      "Validation accuracy: 0.774\n",
      "------------- epoch:  5\n",
      "Training loss: 0.155\n",
      "Validation loss: 0.636\n",
      "Validation accuracy: 0.791\n",
      "------------- epoch:  6\n",
      "Training loss: 0.133\n",
      "Validation loss: 0.528\n",
      "Validation accuracy: 0.831\n",
      "------------- epoch:  7\n",
      "Training loss: 0.133\n",
      "Validation loss: 0.625\n",
      "Validation accuracy: 0.810\n",
      "------------- epoch:  8\n",
      "Training loss: 0.117\n",
      "Validation loss: 0.631\n",
      "Validation accuracy: 0.814\n",
      "------------- epoch:  9\n",
      "Training loss: 0.127\n",
      "Validation loss: 0.581\n",
      "Validation accuracy: 0.833\n",
      "------------- epoch:  10\n",
      "Training loss: 0.106\n",
      "Validation loss: 0.588\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  11\n",
      "Training loss: 0.116\n",
      "Validation loss: 0.656\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  12\n",
      "Training loss: 0.102\n",
      "Validation loss: 0.551\n",
      "Validation accuracy: 0.842\n",
      "------------- epoch:  13\n",
      "Training loss: 0.105\n",
      "Validation loss: 0.620\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  14\n",
      "Training loss: 0.102\n",
      "Validation loss: 0.706\n",
      "Validation accuracy: 0.797\n",
      "------------- epoch:  15\n",
      "Training loss: 0.091\n",
      "Validation loss: 0.596\n",
      "Validation accuracy: 0.831\n",
      "------------- epoch:  16\n",
      "Training loss: 0.081\n",
      "Validation loss: 0.702\n",
      "Validation accuracy: 0.844\n",
      "------------- epoch:  17\n",
      "Training loss: 0.083\n",
      "Validation loss: 0.606\n",
      "Validation accuracy: 0.853\n",
      "------------- epoch:  18\n",
      "Training loss: 0.083\n",
      "Validation loss: 0.645\n",
      "Validation accuracy: 0.836\n",
      "------------- epoch:  19\n",
      "Training loss: 0.094\n",
      "Validation loss: 0.610\n",
      "Validation accuracy: 0.840\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      95.0     100.0\n",
      "Shirts                       98.3     100.0\n",
      "Casual Shoes                 84.0      99.2\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 89.1     100.0\n",
      "Kurtas                       96.6      99.1\n",
      "Tops                         48.7      99.1\n",
      "Handbags                     84.9      99.2\n",
      "Heels                        93.2     100.0\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      96.6     100.0\n",
      "Flip Flops                   83.2      98.2\n",
      "Sandals                      69.0     100.0\n",
      "Briefs                      100.0     100.0\n",
      "Belts                        99.1     100.0\n",
      "Backpacks                    97.4     100.0\n",
      "Socks                        87.6     100.0\n",
      "Formal Shoes                 74.1     100.0\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      84.8      94.7\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0053/model_epoch_17.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighed Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n",
      "Training loss: 0.913\n",
      "Validation loss: 0.793\n",
      "Validation accuracy: 0.728\n",
      "------------- epoch:  1\n",
      "Training loss: 0.545\n",
      "Validation loss: 0.656\n",
      "Validation accuracy: 0.698\n",
      "------------- epoch:  2\n",
      "Training loss: 0.446\n",
      "Validation loss: 0.570\n",
      "Validation accuracy: 0.767\n",
      "------------- epoch:  3\n",
      "Training loss: 0.387\n",
      "Validation loss: 0.699\n",
      "Validation accuracy: 0.787\n",
      "------------- epoch:  4\n",
      "Training loss: 0.370\n",
      "Validation loss: 0.493\n",
      "Validation accuracy: 0.808\n",
      "------------- epoch:  5\n",
      "Training loss: 0.312\n",
      "Validation loss: 0.489\n",
      "Validation accuracy: 0.781\n",
      "------------- epoch:  6\n",
      "Training loss: 0.315\n",
      "Validation loss: 0.514\n",
      "Validation accuracy: 0.810\n",
      "------------- epoch:  7\n",
      "Training loss: 0.306\n",
      "Validation loss: 0.506\n",
      "Validation accuracy: 0.802\n",
      "------------- epoch:  8\n",
      "Training loss: 0.271\n",
      "Validation loss: 0.474\n",
      "Validation accuracy: 0.808\n",
      "------------- epoch:  9\n",
      "Training loss: 0.270\n",
      "Validation loss: 0.524\n",
      "Validation accuracy: 0.806\n",
      "------------- epoch:  10\n",
      "Training loss: 0.255\n",
      "Validation loss: 0.440\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  11\n",
      "Training loss: 0.254\n",
      "Validation loss: 0.411\n",
      "Validation accuracy: 0.825\n",
      "------------- epoch:  12\n",
      "Training loss: 0.239\n",
      "Validation loss: 0.423\n",
      "Validation accuracy: 0.828\n",
      "------------- epoch:  13\n",
      "Training loss: 0.230\n",
      "Validation loss: 0.422\n",
      "Validation accuracy: 0.833\n",
      "------------- epoch:  14\n",
      "Training loss: 0.229\n",
      "Validation loss: 0.477\n",
      "Validation accuracy: 0.799\n",
      "------------- epoch:  15\n",
      "Training loss: 0.219\n",
      "Validation loss: 0.446\n",
      "Validation accuracy: 0.845\n",
      "------------- epoch:  16\n",
      "Training loss: 0.199\n",
      "Validation loss: 0.497\n",
      "Validation accuracy: 0.815\n",
      "------------- epoch:  17\n",
      "Training loss: 0.200\n",
      "Validation loss: 0.446\n",
      "Validation accuracy: 0.838\n",
      "------------- epoch:  18\n",
      "Training loss: 0.199\n",
      "Validation loss: 0.418\n",
      "Validation accuracy: 0.841\n",
      "------------- epoch:  19\n",
      "Training loss: 0.189\n",
      "Validation loss: 0.478\n",
      "Validation accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(weight=torch.tensor(data.weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      94.1     100.0\n",
      "Shirts                       97.5     100.0\n",
      "Casual Shoes                 78.2      98.3\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 88.2     100.0\n",
      "Kurtas                       93.2      99.1\n",
      "Tops                         61.5      99.1\n",
      "Handbags                     93.3      98.3\n",
      "Heels                        81.2      99.1\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      94.0     100.0\n",
      "Flip Flops                   95.6      97.3\n",
      "Sandals                      69.0     100.0\n",
      "Briefs                       93.3     100.0\n",
      "Belts                        99.1      99.1\n",
      "Backpacks                    87.7      98.2\n",
      "Socks                        86.6      94.8\n",
      "Formal Shoes                 83.3      99.1\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      84.7      94.1\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0136/model_epoch_15.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighed Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.575\n",
      "Validation loss: 0.498\n",
      "Validation accuracy: 0.682\n",
      "------------- epoch:  1\n",
      "Training loss: 0.322\n",
      "Validation loss: 0.403\n",
      "Validation accuracy: 0.736\n",
      "------------- epoch:  2\n",
      "Training loss: 0.254\n",
      "Validation loss: 0.321\n",
      "Validation accuracy: 0.748\n",
      "------------- epoch:  3\n",
      "Training loss: 0.229\n",
      "Validation loss: 0.272\n",
      "Validation accuracy: 0.803\n",
      "------------- epoch:  4\n",
      "Training loss: 0.220\n",
      "Validation loss: 0.242\n",
      "Validation accuracy: 0.822\n",
      "------------- epoch:  5\n",
      "Training loss: 0.194\n",
      "Validation loss: 0.296\n",
      "Validation accuracy: 0.800\n",
      "------------- epoch:  6\n",
      "Training loss: 0.179\n",
      "Validation loss: 0.255\n",
      "Validation accuracy: 0.792\n",
      "------------- epoch:  7\n",
      "Training loss: 0.166\n",
      "Validation loss: 0.239\n",
      "Validation accuracy: 0.824\n",
      "------------- epoch:  8\n",
      "Training loss: 0.151\n",
      "Validation loss: 0.276\n",
      "Validation accuracy: 0.785\n",
      "------------- epoch:  9\n",
      "Training loss: 0.155\n",
      "Validation loss: 0.417\n",
      "Validation accuracy: 0.748\n",
      "------------- epoch:  10\n",
      "Training loss: 0.161\n",
      "Validation loss: 0.258\n",
      "Validation accuracy: 0.817\n",
      "------------- epoch:  11\n",
      "Training loss: 0.148\n",
      "Validation loss: 0.239\n",
      "Validation accuracy: 0.811\n",
      "------------- epoch:  12\n",
      "Training loss: 0.139\n",
      "Validation loss: 0.284\n",
      "Validation accuracy: 0.825\n",
      "------------- epoch:  13\n",
      "Training loss: 0.129\n",
      "Validation loss: 0.291\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  14\n",
      "Training loss: 0.131\n",
      "Validation loss: 0.230\n",
      "Validation accuracy: 0.846\n",
      "------------- epoch:  15\n",
      "Training loss: 0.121\n",
      "Validation loss: 0.293\n",
      "Validation accuracy: 0.797\n",
      "------------- epoch:  16\n",
      "Training loss: 0.115\n",
      "Validation loss: 0.316\n",
      "Validation accuracy: 0.804\n",
      "------------- epoch:  17\n",
      "Training loss: 0.125\n",
      "Validation loss: 0.241\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  18\n",
      "Training loss: 0.119\n",
      "Validation loss: 0.230\n",
      "Validation accuracy: 0.837\n",
      "------------- epoch:  19\n",
      "Training loss: 0.106\n",
      "Validation loss: 0.226\n",
      "Validation accuracy: 0.840\n",
      "------------- epoch:  20\n",
      "Training loss: 0.100\n",
      "Validation loss: 0.255\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  21\n",
      "Training loss: 0.107\n",
      "Validation loss: 0.232\n",
      "Validation accuracy: 0.832\n",
      "------------- epoch:  22\n",
      "Training loss: 0.093\n",
      "Validation loss: 0.244\n",
      "Validation accuracy: 0.837\n",
      "------------- epoch:  23\n",
      "Training loss: 0.097\n",
      "Validation loss: 0.208\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  24\n",
      "Training loss: 0.092\n",
      "Validation loss: 0.252\n",
      "Validation accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "normalized_weights = data.n_classes *data.weights /sum(data.weights)\n",
    "\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=.5, alpha=torch.tensor(normalized_weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 25, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      87.4     100.0\n",
      "Shirts                       99.2     100.0\n",
      "Casual Shoes                 81.5      99.2\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 82.4      98.3\n",
      "Kurtas                       88.0     100.0\n",
      "Tops                         76.1     100.0\n",
      "Handbags                     84.9      99.2\n",
      "Heels                        74.4      98.3\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      95.7     100.0\n",
      "Flip Flops                   96.5      97.3\n",
      "Sandals                      61.2     100.0\n",
      "Briefs                       95.5     100.0\n",
      "Belts                       100.0     100.0\n",
      "Backpacks                    97.4     100.0\n",
      "Socks                        90.7      99.0\n",
      "Formal Shoes                 95.4      98.1\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        98.1      99.1\n",
      "===========================================\n",
      "Average                      85.2      94.4\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0231/model_epoch_19.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the *Weighed Focal Loss* performs best here, although the difference between the models could still be due to noise, we're going to run with it and use this model to finetune on the rare classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning on the rare classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/fashion-dataset/styles_quoted.csv',\n",
    "                                '../data/fashion-dataset/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0231/model_epoch_19.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "num_ftrs = model.fc.in_features\n",
    "## replacing the last layer with the dense layer we need\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.773\n",
      "Validation loss: 0.778\n",
      "Validation accuracy: 0.184\n",
      "------------- epoch:  1\n",
      "Training loss: 0.499\n",
      "Validation loss: 0.632\n",
      "Validation accuracy: 0.235\n",
      "------------- epoch:  2\n",
      "Training loss: 0.367\n",
      "Validation loss: 0.577\n",
      "Validation accuracy: 0.305\n",
      "------------- epoch:  3\n",
      "Training loss: 0.304\n",
      "Validation loss: 0.561\n",
      "Validation accuracy: 0.312\n",
      "------------- epoch:  4\n",
      "Training loss: 0.249\n",
      "Validation loss: 0.531\n",
      "Validation accuracy: 0.308\n",
      "------------- epoch:  5\n",
      "Training loss: 0.210\n",
      "Validation loss: 0.573\n",
      "Validation accuracy: 0.249\n",
      "------------- epoch:  6\n",
      "Training loss: 0.203\n",
      "Validation loss: 0.641\n",
      "Validation accuracy: 0.241\n",
      "------------- epoch:  7\n",
      "Training loss: 0.197\n",
      "Validation loss: 0.615\n",
      "Validation accuracy: 0.301\n",
      "------------- epoch:  8\n",
      "Training loss: 0.180\n",
      "Validation loss: 0.590\n",
      "Validation accuracy: 0.322\n",
      "------------- epoch:  9\n",
      "Training loss: 0.135\n",
      "Validation loss: 0.610\n",
      "Validation accuracy: 0.396\n",
      "------------- epoch:  10\n",
      "Training loss: 0.121\n",
      "Validation loss: 0.632\n",
      "Validation accuracy: 0.372\n",
      "------------- epoch:  11\n",
      "Training loss: 0.106\n",
      "Validation loss: 0.683\n",
      "Validation accuracy: 0.355\n",
      "------------- epoch:  12\n",
      "Training loss: 0.099\n",
      "Validation loss: 0.760\n",
      "Validation accuracy: 0.370\n",
      "------------- epoch:  13\n",
      "Training loss: 0.105\n",
      "Validation loss: 0.617\n",
      "Validation accuracy: 0.391\n",
      "------------- epoch:  14\n",
      "Training loss: 0.086\n",
      "Validation loss: 0.658\n",
      "Validation accuracy: 0.406\n",
      "------------- epoch:  15\n",
      "Training loss: 0.080\n",
      "Validation loss: 0.744\n",
      "Validation accuracy: 0.412\n",
      "------------- epoch:  16\n",
      "Training loss: 0.072\n",
      "Validation loss: 0.786\n",
      "Validation accuracy: 0.379\n",
      "------------- epoch:  17\n",
      "Training loss: 0.094\n",
      "Validation loss: 0.828\n",
      "Validation accuracy: 0.398\n",
      "------------- epoch:  18\n",
      "Training loss: 0.099\n",
      "Validation loss: 0.690\n",
      "Validation accuracy: 0.384\n",
      "------------- epoch:  19\n",
      "Training loss: 0.100\n",
      "Validation loss: 0.832\n",
      "Validation accuracy: 0.337\n",
      "------------- epoch:  20\n",
      "Training loss: 0.081\n",
      "Validation loss: 0.799\n",
      "Validation accuracy: 0.387\n",
      "------------- epoch:  21\n",
      "Training loss: 0.070\n",
      "Validation loss: 0.706\n",
      "Validation accuracy: 0.355\n",
      "------------- epoch:  22\n",
      "Training loss: 0.064\n",
      "Validation loss: 0.897\n",
      "Validation accuracy: 0.422\n",
      "------------- epoch:  23\n",
      "Training loss: 0.055\n",
      "Validation loss: 0.814\n",
      "Validation accuracy: 0.423\n",
      "------------- epoch:  24\n",
      "Training loss: 0.056\n",
      "Validation loss: 0.879\n",
      "Validation accuracy: 0.408\n",
      "------------- epoch:  25\n",
      "Training loss: 0.052\n",
      "Validation loss: 0.693\n",
      "Validation accuracy: 0.412\n",
      "------------- epoch:  26\n",
      "Training loss: 0.043\n",
      "Validation loss: 0.778\n",
      "Validation accuracy: 0.432\n",
      "------------- epoch:  27\n",
      "Training loss: 0.041\n",
      "Validation loss: 0.985\n",
      "Validation accuracy: 0.399\n",
      "------------- epoch:  28\n",
      "Training loss: 0.070\n",
      "Validation loss: 0.858\n",
      "Validation accuracy: 0.385\n",
      "------------- epoch:  29\n",
      "Training loss: 0.090\n",
      "Validation loss: 0.736\n",
      "Validation accuracy: 0.305\n",
      "------------- epoch:  30\n",
      "Training loss: 0.154\n",
      "Validation loss: 0.890\n",
      "Validation accuracy: 0.318\n",
      "------------- epoch:  31\n",
      "Training loss: 0.143\n",
      "Validation loss: 0.690\n",
      "Validation accuracy: 0.378\n",
      "------------- epoch:  32\n",
      "Training loss: 0.086\n",
      "Validation loss: 0.659\n",
      "Validation accuracy: 0.379\n",
      "------------- epoch:  33\n",
      "Training loss: 0.078\n",
      "Validation loss: 0.739\n",
      "Validation accuracy: 0.376\n",
      "------------- epoch:  34\n",
      "Training loss: 0.066\n",
      "Validation loss: 0.778\n",
      "Validation accuracy: 0.408\n"
     ]
    }
   ],
   "source": [
    "normalized_weights = data.n_classes *data.weights /sum(data.weights)\n",
    "\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=.5, alpha=torch.tensor(normalized_weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 35, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Jeans                        89.3     100.0\n",
      "Trousers                     60.7     100.0\n",
      "Flats                        85.7     100.0\n",
      "Bra                          92.9      96.4\n",
      "Dresses                      28.0      68.0\n",
      "Earrings                    100.0     100.0\n",
      "Track Pants                  77.8     100.0\n",
      "Deodorant                     0.0       0.0\n",
      "Nail Polish                   0.0       0.0\n",
      "Sweatshirts                  67.9      92.9\n",
      "Clutches                     75.0     100.0\n",
      "Innerwear Vests               0.0     100.0\n",
      "Lipstick                      0.0       0.0\n",
      "Sweaters                     39.3      78.6\n",
      "Jackets                      44.0      88.0\n",
      "Ties                         95.2      95.2\n",
      "Caps                         85.2     100.0\n",
      "Kurtis                       40.0      92.0\n",
      "Tunics                       27.8     100.0\n",
      "Capris                       55.0      85.0\n",
      "Pendant                      47.6      90.5\n",
      "Necklace and Chains          91.7     100.0\n",
      "Dupatta                      50.0     100.0\n",
      "Scarves                      15.0      90.0\n",
      "Leggings                     30.8      69.2\n",
      "Night suits                  52.2      91.3\n",
      "Ring                        100.0     100.0\n",
      "Nightdress                   15.4      53.8\n",
      "Lip Gloss                     0.0       0.0\n",
      "Kajal and Eyeliner            0.0       0.0\n",
      "Stoles                       25.0     100.0\n",
      "Skirts                       75.0      93.8\n",
      "Duffel Bag                   66.7      85.7\n",
      "Free Gifts                    0.0      42.9\n",
      "Bangle                       21.4      64.3\n",
      "Face Moisturisers             0.0       0.0\n",
      "Kurta Sets                   84.6     100.0\n",
      "Cufflinks                   100.0     100.0\n",
      "Accessory Gift Set          100.0     100.0\n",
      "Foundation and Primer         0.0       0.0\n",
      "Sports Sandals               66.7     100.0\n",
      "Lounge Pants                 20.0      60.0\n",
      "Highlighter and Blush         0.0       0.0\n",
      "Laptop Bag                   42.9      85.7\n",
      "Bracelet                     76.9      92.3\n",
      "Jewellery Set               100.0     100.0\n",
      "Compact                       0.0       0.0\n",
      "Eyeshadow                     0.0       0.0\n",
      "Mobile Pouch                 16.7      66.7\n",
      "Fragrance Gift Set            0.0       0.0\n",
      "Lip Liner                     0.0       0.0\n",
      "Camisoles                    40.0      93.3\n",
      "Lounge Shorts                 0.0      14.3\n",
      "Messenger Bag                50.0      66.7\n",
      "Churidar                      0.0      50.0\n",
      "Tracksuits                   92.3     100.0\n",
      "Stockings                     0.0      10.0\n",
      "Mufflers                     55.6     100.0\n",
      "Bath Robe                     0.0       0.0\n",
      "Hair Colour                   0.0       0.0\n",
      "Shoe Accessories              0.0      18.2\n",
      "Gloves                      100.0     100.0\n",
      "Lip Care                      0.0       0.0\n",
      "Baby Dolls                    0.0       0.0\n",
      "Face Wash and Cleanser        0.0       0.0\n",
      "Waistcoat                   100.0     100.0\n",
      "Sunscreen                     0.0       0.0\n",
      "Basketballs                   0.0       0.0\n",
      "Swimwear                     25.0      50.0\n",
      "Concealer                     0.0       0.0\n",
      "Shapewear                     0.0       0.0\n",
      "Mascara                       0.0       0.0\n",
      "Rucksacks                   100.0     100.0\n",
      "Waist Pouch                   0.0       0.0\n",
      "Body Lotion                   0.0       0.0\n",
      "Mask and Peel                 0.0       0.0\n",
      "Tights                      100.0     100.0\n",
      "Footballs                   100.0     100.0\n",
      "Travel Accessory              0.0       0.0\n",
      "Lip Plumper                   0.0       0.0\n",
      "Eye Cream                     0.0       0.0\n",
      "Headband                      0.0       0.0\n",
      "Beauty Accessory              0.0       0.0\n",
      "Robe                          0.0       0.0\n",
      "Face Scrub and Exfoliator       0.0       0.0\n",
      "Nail Essentials               0.0       0.0\n",
      "Hat                           0.0       0.0\n",
      "Toner                         0.0       0.0\n",
      "Shrug                         0.0       0.0\n",
      "Makeup Remover                0.0       0.0\n",
      "Wristbands                    0.0       0.0\n",
      "Ties and Cufflinks            0.0       0.0\n",
      "Key chain                     0.0       0.0\n",
      "Umbrellas                     0.0       0.0\n",
      "Face Serum and Gel            0.0       0.0\n",
      "Shoe Laces                    0.0       0.0\n",
      "Mens Grooming Kit             0.0       0.0\n",
      "Body Wash and Scrub           0.0       0.0\n",
      "===========================================\n",
      "Average                      30.9      45.8\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_1537/model_epoch_34.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare this to not finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/fashion-dataset/styles_quoted.csv',\n",
    "                                '../data/fashion-dataset/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_weights = data.n_classes *data.weights /sum(data.weights)\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=.5, alpha=torch.tensor(normalized_weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.900\n",
      "Validation loss: 17.175\n",
      "Validation accuracy: 0.010\n",
      "------------- epoch:  1\n",
      "Training loss: 0.912\n",
      "Validation loss: 1.157\n",
      "Validation accuracy: 0.003\n",
      "------------- epoch:  2\n",
      "Training loss: 0.826\n",
      "Validation loss: 0.951\n",
      "Validation accuracy: 0.050\n",
      "------------- epoch:  3\n",
      "Training loss: 0.788\n",
      "Validation loss: 0.937\n",
      "Validation accuracy: 0.005\n",
      "------------- epoch:  4\n",
      "Training loss: 0.756\n",
      "Validation loss: 0.939\n",
      "Validation accuracy: 0.005\n",
      "------------- epoch:  5\n",
      "Training loss: 0.743\n",
      "Validation loss: 0.942\n",
      "Validation accuracy: 0.045\n",
      "------------- epoch:  6\n",
      "Training loss: 0.727\n",
      "Validation loss: 1.918\n",
      "Validation accuracy: 0.036\n",
      "------------- epoch:  7\n",
      "Training loss: 0.692\n",
      "Validation loss: 0.878\n",
      "Validation accuracy: 0.045\n",
      "------------- epoch:  8\n",
      "Training loss: 0.628\n",
      "Validation loss: 0.829\n",
      "Validation accuracy: 0.109\n",
      "------------- epoch:  9\n",
      "Training loss: 0.615\n",
      "Validation loss: 0.883\n",
      "Validation accuracy: 0.087\n",
      "------------- epoch:  10\n",
      "Training loss: 0.577\n",
      "Validation loss: 0.946\n",
      "Validation accuracy: 0.037\n",
      "------------- epoch:  11\n",
      "Training loss: 0.547\n",
      "Validation loss: 1.091\n",
      "Validation accuracy: 0.062\n",
      "------------- epoch:  12\n",
      "Training loss: 0.522\n",
      "Validation loss: 0.880\n",
      "Validation accuracy: 0.116\n",
      "------------- epoch:  13\n",
      "Training loss: 0.493\n",
      "Validation loss: 0.921\n",
      "Validation accuracy: 0.080\n",
      "------------- epoch:  14\n",
      "Training loss: 0.490\n",
      "Validation loss: 0.880\n",
      "Validation accuracy: 0.118\n",
      "------------- epoch:  15\n",
      "Training loss: 0.472\n",
      "Validation loss: 0.863\n",
      "Validation accuracy: 0.103\n",
      "------------- epoch:  16\n",
      "Training loss: 0.442\n",
      "Validation loss: 1.252\n",
      "Validation accuracy: 0.076\n",
      "------------- epoch:  17\n",
      "Training loss: 0.430\n",
      "Validation loss: 0.850\n",
      "Validation accuracy: 0.121\n",
      "------------- epoch:  18\n",
      "Training loss: 0.418\n",
      "Validation loss: 1.120\n",
      "Validation accuracy: 0.085\n",
      "------------- epoch:  19\n",
      "Training loss: 0.388\n",
      "Validation loss: 0.778\n",
      "Validation accuracy: 0.189\n",
      "------------- epoch:  20\n",
      "Training loss: 0.368\n",
      "Validation loss: 0.827\n",
      "Validation accuracy: 0.152\n",
      "------------- epoch:  21\n",
      "Training loss: 0.347\n",
      "Validation loss: 1.057\n",
      "Validation accuracy: 0.099\n",
      "------------- epoch:  22\n",
      "Training loss: 0.364\n",
      "Validation loss: 0.758\n",
      "Validation accuracy: 0.185\n",
      "------------- epoch:  23\n",
      "Training loss: 0.348\n",
      "Validation loss: 0.839\n",
      "Validation accuracy: 0.132\n",
      "------------- epoch:  24\n",
      "Training loss: 0.326\n",
      "Validation loss: 0.862\n",
      "Validation accuracy: 0.206\n",
      "------------- epoch:  25\n",
      "Training loss: 0.318\n",
      "Validation loss: 0.801\n",
      "Validation accuracy: 0.235\n",
      "------------- epoch:  26\n",
      "Training loss: 0.296\n",
      "Validation loss: 0.727\n",
      "Validation accuracy: 0.216\n",
      "------------- epoch:  27\n",
      "Training loss: 0.291\n",
      "Validation loss: 1.235\n",
      "Validation accuracy: 0.092\n",
      "------------- epoch:  28\n",
      "Training loss: 0.305\n",
      "Validation loss: 1.107\n",
      "Validation accuracy: 0.099\n",
      "------------- epoch:  29\n",
      "Training loss: 0.265\n",
      "Validation loss: 0.821\n",
      "Validation accuracy: 0.237\n",
      "------------- epoch:  30\n",
      "Training loss: 0.254\n",
      "Validation loss: 1.171\n",
      "Validation accuracy: 0.118\n",
      "------------- epoch:  31\n",
      "Training loss: 0.232\n",
      "Validation loss: 0.891\n",
      "Validation accuracy: 0.169\n",
      "------------- epoch:  32\n",
      "Training loss: 0.239\n",
      "Validation loss: 1.846\n",
      "Validation accuracy: 0.045\n",
      "------------- epoch:  33\n",
      "Training loss: 0.234\n",
      "Validation loss: 1.205\n",
      "Validation accuracy: 0.111\n",
      "------------- epoch:  34\n",
      "Training loss: 0.239\n",
      "Validation loss: 0.752\n",
      "Validation accuracy: 0.276\n"
     ]
    }
   ],
   "source": [
    "fewshot.trainer.run_training(model, 35, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Jeans                        64.3      92.9\n",
      "Trousers                     78.6      96.4\n",
      "Flats                        53.6      96.4\n",
      "Bra                          57.1      96.4\n",
      "Dresses                      36.0      64.0\n",
      "Earrings                     61.1     100.0\n",
      "Track Pants                  59.3      88.9\n",
      "Deodorant                     0.0       0.0\n",
      "Nail Polish                   0.0       0.0\n",
      "Sweatshirts                  25.0      89.3\n",
      "Clutches                     75.0      83.3\n",
      "Innerwear Vests               0.0       0.0\n",
      "Lipstick                      0.0       0.0\n",
      "Sweaters                     21.4      71.4\n",
      "Jackets                      12.0      68.0\n",
      "Ties                         90.5      95.2\n",
      "Caps                         59.3      81.5\n",
      "Kurtis                        4.0      80.0\n",
      "Tunics                       33.3      88.9\n",
      "Capris                       10.0      70.0\n",
      "Pendant                      47.6     100.0\n",
      "Necklace and Chains          58.3      91.7\n",
      "Dupatta                       0.0      50.0\n",
      "Scarves                      25.0      85.0\n",
      "Leggings                     30.8      61.5\n",
      "Night suits                  47.8      87.0\n",
      "Ring                         53.8     100.0\n",
      "Nightdress                    0.0      50.0\n",
      "Lip Gloss                     0.0       0.0\n",
      "Kajal and Eyeliner            0.0       0.0\n",
      "Stoles                        0.0      50.0\n",
      "Skirts                       12.5      68.8\n",
      "Duffel Bag                   33.3      57.1\n",
      "Free Gifts                    0.0      28.6\n",
      "Bangle                        0.0      57.1\n",
      "Face Moisturisers             0.0       0.0\n",
      "Kurta Sets                   92.3     100.0\n",
      "Cufflinks                    18.2     100.0\n",
      "Accessory Gift Set           55.0     100.0\n",
      "Foundation and Primer         0.0       0.0\n",
      "Sports Sandals               16.7      91.7\n",
      "Lounge Pants                  0.0      30.0\n",
      "Highlighter and Blush         0.0       0.0\n",
      "Laptop Bag                    0.0      71.4\n",
      "Bracelet                     61.5      92.3\n",
      "Jewellery Set                77.8     100.0\n",
      "Compact                       0.0       0.0\n",
      "Eyeshadow                     0.0       0.0\n",
      "Mobile Pouch                  8.3      16.7\n",
      "Fragrance Gift Set            0.0       0.0\n",
      "Lip Liner                     0.0       0.0\n",
      "Camisoles                    40.0      93.3\n",
      "Lounge Shorts                 0.0      57.1\n",
      "Messenger Bag                 0.0      66.7\n",
      "Churidar                      0.0      50.0\n",
      "Tracksuits                   53.8     100.0\n",
      "Stockings                     0.0      70.0\n",
      "Mufflers                     11.1      66.7\n",
      "Bath Robe                     0.0       0.0\n",
      "Hair Colour                   0.0       0.0\n",
      "Shoe Accessories              9.1      27.3\n",
      "Gloves                       50.0      50.0\n",
      "Lip Care                      0.0       0.0\n",
      "Baby Dolls                    0.0       0.0\n",
      "Face Wash and Cleanser        0.0       0.0\n",
      "Waistcoat                     0.0      20.0\n",
      "Sunscreen                     0.0       0.0\n",
      "Basketballs                   0.0       0.0\n",
      "Swimwear                     25.0      25.0\n",
      "Concealer                     0.0       0.0\n",
      "Shapewear                     0.0       0.0\n",
      "Mascara                       0.0       0.0\n",
      "Rucksacks                    40.0      40.0\n",
      "Waist Pouch                   0.0       0.0\n",
      "Body Lotion                   0.0       0.0\n",
      "Mask and Peel                 0.0       0.0\n",
      "Tights                        0.0       0.0\n",
      "Footballs                   100.0     100.0\n",
      "Travel Accessory              0.0       0.0\n",
      "Lip Plumper                   0.0       0.0\n",
      "Eye Cream                     0.0       0.0\n",
      "Headband                      0.0       0.0\n",
      "Beauty Accessory              0.0       0.0\n",
      "Robe                          0.0       0.0\n",
      "Face Scrub and Exfoliator       0.0       0.0\n",
      "Nail Essentials               0.0       0.0\n",
      "Hat                           0.0       0.0\n",
      "Toner                         0.0       0.0\n",
      "Shrug                         0.0       0.0\n",
      "Makeup Remover                0.0       0.0\n",
      "Wristbands                    0.0       0.0\n",
      "Ties and Cufflinks            0.0       0.0\n",
      "Key chain                     0.0     100.0\n",
      "Umbrellas                     0.0       0.0\n",
      "Face Serum and Gel            0.0       0.0\n",
      "Shoe Laces                    0.0       0.0\n",
      "Mens Grooming Kit             0.0       0.0\n",
      "Body Wash and Scrub           0.0       0.0\n",
      "===========================================\n",
      "Average                      17.4      39.0\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun10_1108/model_epoch_34.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, occ, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
