{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import fewshot.data\n",
    "import fewshot.trainer\n",
    "import fewshot.focal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring tests on small dataset\n",
    "We've refactored our data pipeline, utilites and training loop in the `fewshot` module. Let's test it below for a full run of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot.data.fix_quotes('../data/fashion-dataset/styles.csv', '../data/fashion-dataset/styles_quoted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(300),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/small/styles_quoted.csv',\n",
    "                                '../data/small/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "## replacing the last layer with the dense layer we need\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which loss performs better on top20?\n",
    "### Plain Cross-Entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n",
      "Training loss: 0.732\n",
      "Validation loss: 1.064\n",
      "Validation accuracy: 0.737\n",
      "------------- epoch:  1\n",
      "Training loss: 0.450\n",
      "Validation loss: 0.975\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  2\n",
      "Training loss: 0.386\n",
      "Validation loss: 0.976\n",
      "Validation accuracy: 0.795\n",
      "------------- epoch:  3\n",
      "Training loss: 0.349\n",
      "Validation loss: 1.057\n",
      "Validation accuracy: 0.816\n",
      "------------- epoch:  4\n",
      "Training loss: 0.320\n",
      "Validation loss: 0.821\n",
      "Validation accuracy: 0.817\n",
      "------------- epoch:  5\n",
      "Training loss: 0.281\n",
      "Validation loss: 1.153\n",
      "Validation accuracy: 0.792\n",
      "------------- epoch:  6\n",
      "Training loss: 0.284\n",
      "Validation loss: 0.853\n",
      "Validation accuracy: 0.840\n",
      "------------- epoch:  7\n",
      "Training loss: 0.259\n",
      "Validation loss: 0.959\n",
      "Validation accuracy: 0.837\n",
      "------------- epoch:  8\n",
      "Training loss: 0.241\n",
      "Validation loss: 0.900\n",
      "Validation accuracy: 0.842\n",
      "------------- epoch:  9\n",
      "Training loss: 0.243\n",
      "Validation loss: 0.930\n",
      "Validation accuracy: 0.832\n",
      "------------- epoch:  10\n",
      "Training loss: 0.225\n",
      "Validation loss: 1.335\n",
      "Validation accuracy: 0.739\n",
      "------------- epoch:  11\n",
      "Training loss: 0.221\n",
      "Validation loss: 1.120\n",
      "Validation accuracy: 0.825\n",
      "------------- epoch:  12\n",
      "Training loss: 0.209\n",
      "Validation loss: 1.035\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  13\n",
      "Training loss: 0.208\n",
      "Validation loss: 0.962\n",
      "Validation accuracy: 0.847\n",
      "------------- epoch:  14\n",
      "Training loss: 0.205\n",
      "Validation loss: 1.031\n",
      "Validation accuracy: 0.839\n",
      "------------- epoch:  15\n",
      "Training loss: 0.182\n",
      "Validation loss: 0.947\n",
      "Validation accuracy: 0.857\n",
      "------------- epoch:  16\n",
      "Training loss: 0.187\n",
      "Validation loss: 0.985\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  17\n",
      "Training loss: 0.181\n",
      "Validation loss: 0.904\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  18\n",
      "Training loss: 0.169\n",
      "Validation loss: 0.982\n",
      "Validation accuracy: 0.848\n",
      "------------- epoch:  19\n",
      "Training loss: 0.166\n",
      "Validation loss: 1.040\n",
      "Validation accuracy: 0.846\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      89.1      99.2\n",
      "Shirts                       98.3     100.0\n",
      "Casual Shoes                 86.6      98.3\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 73.9     100.0\n",
      "Kurtas                       94.9      99.1\n",
      "Tops                         66.7     100.0\n",
      "Handbags                     95.0      99.2\n",
      "Heels                        89.7      99.1\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      95.7      99.1\n",
      "Flip Flops                   87.6      96.5\n",
      "Sandals                      78.4     100.0\n",
      "Briefs                       95.5     100.0\n",
      "Belts                        97.3      99.1\n",
      "Backpacks                    84.2      99.1\n",
      "Socks                        77.3      93.8\n",
      "Formal Shoes                 77.8      99.1\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      84.4      94.1\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun09_0014/model_epoch_18.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.463\n",
      "Validation loss: 0.766\n",
      "Validation accuracy: 0.690\n",
      "------------- epoch:  1\n",
      "Training loss: 0.274\n",
      "Validation loss: 0.628\n",
      "Validation accuracy: 0.772\n",
      "------------- epoch:  2\n",
      "Training loss: 0.209\n",
      "Validation loss: 0.604\n",
      "Validation accuracy: 0.779\n",
      "------------- epoch:  3\n",
      "Training loss: 0.173\n",
      "Validation loss: 0.640\n",
      "Validation accuracy: 0.788\n",
      "------------- epoch:  4\n",
      "Training loss: 0.159\n",
      "Validation loss: 0.620\n",
      "Validation accuracy: 0.774\n",
      "------------- epoch:  5\n",
      "Training loss: 0.155\n",
      "Validation loss: 0.636\n",
      "Validation accuracy: 0.791\n",
      "------------- epoch:  6\n",
      "Training loss: 0.133\n",
      "Validation loss: 0.528\n",
      "Validation accuracy: 0.831\n",
      "------------- epoch:  7\n",
      "Training loss: 0.133\n",
      "Validation loss: 0.625\n",
      "Validation accuracy: 0.810\n",
      "------------- epoch:  8\n",
      "Training loss: 0.117\n",
      "Validation loss: 0.631\n",
      "Validation accuracy: 0.814\n",
      "------------- epoch:  9\n",
      "Training loss: 0.127\n",
      "Validation loss: 0.581\n",
      "Validation accuracy: 0.833\n",
      "------------- epoch:  10\n",
      "Training loss: 0.106\n",
      "Validation loss: 0.588\n",
      "Validation accuracy: 0.835\n",
      "------------- epoch:  11\n",
      "Training loss: 0.116\n",
      "Validation loss: 0.656\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  12\n",
      "Training loss: 0.102\n",
      "Validation loss: 0.551\n",
      "Validation accuracy: 0.842\n",
      "------------- epoch:  13\n",
      "Training loss: 0.105\n",
      "Validation loss: 0.620\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  14\n",
      "Training loss: 0.102\n",
      "Validation loss: 0.706\n",
      "Validation accuracy: 0.797\n",
      "------------- epoch:  15\n",
      "Training loss: 0.091\n",
      "Validation loss: 0.596\n",
      "Validation accuracy: 0.831\n",
      "------------- epoch:  16\n",
      "Training loss: 0.081\n",
      "Validation loss: 0.702\n",
      "Validation accuracy: 0.844\n",
      "------------- epoch:  17\n",
      "Training loss: 0.083\n",
      "Validation loss: 0.606\n",
      "Validation accuracy: 0.853\n",
      "------------- epoch:  18\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      94.1     100.0\n",
      "Shirts                       99.2     100.0\n",
      "Casual Shoes                 91.6      98.3\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 66.4      98.3\n",
      "Kurtas                       96.6     100.0\n",
      "Tops                         66.7     100.0\n",
      "Handbags                     92.4      99.2\n",
      "Heels                        84.6      97.4\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      87.2     100.0\n",
      "Flip Flops                   87.6      96.5\n",
      "Sandals                      80.2     100.0\n",
      "Briefs                       96.6     100.0\n",
      "Belts                        99.1      99.1\n",
      "Backpacks                    94.7     100.0\n",
      "Socks                        80.4      96.9\n",
      "Formal Shoes                 74.1      99.1\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      84.5      94.2\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun08_1016/model_epoch_14.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighed Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n",
      "Training loss: 0.875\n",
      "Validation loss: 0.992\n",
      "Validation accuracy: 0.637\n",
      "------------- epoch:  1\n",
      "Training loss: 0.544\n",
      "Validation loss: 0.707\n",
      "Validation accuracy: 0.698\n",
      "------------- epoch:  2\n",
      "Training loss: 0.463\n",
      "Validation loss: 0.504\n",
      "Validation accuracy: 0.767\n",
      "------------- epoch:  3\n",
      "Training loss: 0.370\n",
      "Validation loss: 0.488\n",
      "Validation accuracy: 0.783\n",
      "------------- epoch:  4\n",
      "Training loss: 0.345\n",
      "Validation loss: 0.482\n",
      "Validation accuracy: 0.799\n",
      "------------- epoch:  5\n",
      "Training loss: 0.335\n",
      "Validation loss: 0.489\n",
      "Validation accuracy: 0.785\n",
      "------------- epoch:  6\n",
      "Training loss: 0.300\n",
      "Validation loss: 0.479\n",
      "Validation accuracy: 0.816\n",
      "------------- epoch:  7\n",
      "Training loss: 0.289\n",
      "Validation loss: 0.407\n",
      "Validation accuracy: 0.837\n",
      "------------- epoch:  8\n",
      "Training loss: 0.278\n",
      "Validation loss: 0.427\n",
      "Validation accuracy: 0.801\n",
      "------------- epoch:  9\n",
      "Training loss: 0.262\n",
      "Validation loss: 0.507\n",
      "Validation accuracy: 0.808\n",
      "------------- epoch:  10\n",
      "Training loss: 0.264\n",
      "Validation loss: 0.436\n",
      "Validation accuracy: 0.811\n",
      "------------- epoch:  11\n",
      "Training loss: 0.246\n",
      "Validation loss: 1.261\n",
      "Validation accuracy: 0.680\n",
      "------------- epoch:  12\n",
      "Training loss: 0.225\n",
      "Validation loss: 0.400\n",
      "Validation accuracy: 0.831\n",
      "------------- epoch:  13\n",
      "Training loss: 0.220\n",
      "Validation loss: 0.504\n",
      "Validation accuracy: 0.800\n",
      "------------- epoch:  14\n",
      "Training loss: 0.224\n",
      "Validation loss: 0.403\n",
      "Validation accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(weight=torch.tensor(data.weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 15, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      85.7     100.0\n",
      "Shirts                      100.0     100.0\n",
      "Casual Shoes                 79.0      98.3\n",
      "Watches                     100.0     100.0\n",
      "Sports Shoes                 78.2     100.0\n",
      "Kurtas                       86.3      99.1\n",
      "Tops                         72.6     100.0\n",
      "Handbags                     95.8      97.5\n",
      "Heels                        85.5      99.1\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      94.0      99.1\n",
      "Flip Flops                   90.3      97.3\n",
      "Sandals                      80.2      99.1\n",
      "Briefs                       95.5     100.0\n",
      "Belts                       100.0      98.2\n",
      "Backpacks                    93.0     100.0\n",
      "Socks                        86.6      93.8\n",
      "Formal Shoes                 97.2     100.0\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1     100.0\n",
      "===========================================\n",
      "Average                      85.9      94.1\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun08_1445//model_epoch_14.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighed Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fewshot/focal.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logpt = F.log_softmax(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.027\n",
      "Validation loss: 0.037\n",
      "Validation accuracy: 0.620\n",
      "------------- epoch:  1\n",
      "Training loss: 0.018\n",
      "Validation loss: 0.022\n",
      "Validation accuracy: 0.719\n",
      "------------- epoch:  2\n",
      "Training loss: 0.013\n",
      "Validation loss: 0.021\n",
      "Validation accuracy: 0.757\n",
      "------------- epoch:  3\n",
      "Training loss: 0.012\n",
      "Validation loss: 0.022\n",
      "Validation accuracy: 0.728\n",
      "------------- epoch:  4\n",
      "Training loss: 0.011\n",
      "Validation loss: 0.014\n",
      "Validation accuracy: 0.783\n",
      "------------- epoch:  5\n",
      "Training loss: 0.010\n",
      "Validation loss: 0.011\n",
      "Validation accuracy: 0.824\n",
      "------------- epoch:  6\n",
      "Training loss: 0.009\n",
      "Validation loss: 0.011\n",
      "Validation accuracy: 0.821\n",
      "------------- epoch:  7\n",
      "Training loss: 0.009\n",
      "Validation loss: 0.014\n",
      "Validation accuracy: 0.794\n",
      "------------- epoch:  8\n",
      "Training loss: 0.008\n",
      "Validation loss: 0.012\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  9\n",
      "Training loss: 0.008\n",
      "Validation loss: 0.015\n",
      "Validation accuracy: 0.808\n",
      "------------- epoch:  10\n",
      "Training loss: 0.008\n",
      "Validation loss: 0.012\n",
      "Validation accuracy: 0.798\n",
      "------------- epoch:  11\n",
      "Training loss: 0.007\n",
      "Validation loss: 0.010\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  12\n",
      "Training loss: 0.007\n",
      "Validation loss: 0.011\n",
      "Validation accuracy: 0.831\n",
      "------------- epoch:  13\n",
      "Training loss: 0.007\n",
      "Validation loss: 0.012\n",
      "Validation accuracy: 0.792\n",
      "------------- epoch:  14\n",
      "Training loss: 0.007\n",
      "Validation loss: 0.010\n",
      "Validation accuracy: 0.852\n",
      "------------- epoch:  15\n",
      "Training loss: 0.006\n",
      "Validation loss: 0.012\n",
      "Validation accuracy: 0.832\n",
      "------------- epoch:  16\n",
      "Training loss: 0.007\n",
      "Validation loss: 0.012\n",
      "Validation accuracy: 0.841\n",
      "------------- epoch:  17\n",
      "Training loss: 0.006\n",
      "Validation loss: 0.011\n",
      "Validation accuracy: 0.829\n",
      "------------- epoch:  18\n",
      "Training loss: 0.005\n",
      "Validation loss: 0.015\n",
      "Validation accuracy: 0.814\n",
      "------------- epoch:  19\n",
      "Training loss: 0.006\n",
      "Validation loss: 0.012\n",
      "Validation accuracy: 0.821\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "normalized_weights = data.n_classes *data.weights /sum(data.weights)\n",
    "\n",
    "loss_func = fewshot.focal.FocalLoss(gamma=.5, alpha=torch.tensor(normalized_weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Tshirts                      89.9     100.0\n",
      "Shirts                       98.3     100.0\n",
      "Casual Shoes                 80.7      97.5\n",
      "Watches                      98.0     100.0\n",
      "Sports Shoes                 79.8     100.0\n",
      "Kurtas                       97.4     100.0\n",
      "Tops                         61.5      96.6\n",
      "Handbags                     90.8      96.6\n",
      "Heels                        81.2      96.6\n",
      "Sunglasses                  100.0     100.0\n",
      "Wallets                      98.3     100.0\n",
      "Flip Flops                   85.8      99.1\n",
      "Sandals                      76.7     100.0\n",
      "Briefs                       94.4     100.0\n",
      "Belts                        98.2      99.1\n",
      "Backpacks                    96.5     100.0\n",
      "Socks                        93.8      97.9\n",
      "Formal Shoes                 97.2     100.0\n",
      "Perfume and Body Mist         0.0       0.0\n",
      "Jeans                        99.1      99.1\n",
      "===========================================\n",
      "Average                      85.9      94.1\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun08_1520/model_epoch_14.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning on the rare classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/small/styles_quoted.csv',\n",
    "                                '../data/small/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun08_1520/model_epoch_14.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "num_ftrs = model.fc.in_features\n",
    "## replacing the last layer with the dense layer we need\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n",
      "Training loss: 1.942\n",
      "Validation loss: 5.685\n",
      "Validation accuracy: 0.318\n",
      "------------- epoch:  1\n",
      "Training loss: 1.100\n",
      "Validation loss: 6.191\n",
      "Validation accuracy: 0.245\n",
      "------------- epoch:  2\n",
      "Training loss: 0.941\n",
      "Validation loss: 5.419\n",
      "Validation accuracy: 0.375\n",
      "------------- epoch:  3\n",
      "Training loss: 0.828\n",
      "Validation loss: 5.926\n",
      "Validation accuracy: 0.380\n",
      "------------- epoch:  4\n",
      "Training loss: 0.730\n",
      "Validation loss: 6.212\n",
      "Validation accuracy: 0.397\n",
      "------------- epoch:  5\n",
      "Training loss: 0.707\n",
      "Validation loss: 6.316\n",
      "Validation accuracy: 0.393\n",
      "------------- epoch:  6\n",
      "Training loss: 0.633\n",
      "Validation loss: 5.438\n",
      "Validation accuracy: 0.416\n",
      "------------- epoch:  7\n",
      "Training loss: 0.615\n",
      "Validation loss: 5.987\n",
      "Validation accuracy: 0.409\n",
      "------------- epoch:  8\n",
      "Training loss: 0.555\n",
      "Validation loss: 5.831\n",
      "Validation accuracy: 0.416\n",
      "------------- epoch:  9\n",
      "Training loss: 0.532\n",
      "Validation loss: 6.640\n",
      "Validation accuracy: 0.379\n",
      "------------- epoch:  10\n",
      "Training loss: 0.511\n",
      "Validation loss: 6.096\n",
      "Validation accuracy: 0.418\n",
      "------------- epoch:  11\n",
      "Training loss: 0.457\n",
      "Validation loss: 6.421\n",
      "Validation accuracy: 0.399\n",
      "------------- epoch:  12\n",
      "Training loss: 0.422\n",
      "Validation loss: 6.466\n",
      "Validation accuracy: 0.433\n",
      "------------- epoch:  13\n",
      "Training loss: 0.413\n",
      "Validation loss: 6.802\n",
      "Validation accuracy: 0.430\n",
      "------------- epoch:  14\n",
      "Training loss: 0.400\n",
      "Validation loss: 7.275\n",
      "Validation accuracy: 0.396\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 15, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Shorts                       83.7      95.3\n",
      "Trousers                     83.7      95.3\n",
      "Flats                        85.7     100.0\n",
      "Bra                         100.0     100.0\n",
      "Dresses                      64.9      83.8\n",
      "Sarees                        nan       nan\n",
      "Earrings                    100.0     100.0\n",
      "Deodorant                     0.0       0.0\n",
      "Nail Polish                   0.0       0.0\n",
      "Lipstick                      0.0       0.0\n",
      "Track Pants                  74.4      97.7\n",
      "Clutches                     78.8      93.9\n",
      "Sweatshirts                  46.5      97.7\n",
      "Caps                         87.5      95.0\n",
      "Sweaters                     55.8      86.0\n",
      "Ties                         91.2      94.1\n",
      "Jackets                      86.0      97.7\n",
      "Innerwear Vests               0.0       0.0\n",
      "Kurtis                       71.4     100.0\n",
      "Tunics                        7.7      92.3\n",
      "Nightdress                    7.1      64.3\n",
      "Leggings                     50.0      84.6\n",
      "Pendant                      70.6      94.1\n",
      "Capris                       57.6      97.0\n",
      "Necklace and Chains          81.0     100.0\n",
      "Lip Gloss                     0.0       0.0\n",
      "Night suits                  34.4      84.4\n",
      "Trunk                         nan       nan\n",
      "Skirts                       38.7      61.3\n",
      "Scarves                      84.0      84.0\n",
      "Ring                         85.0     100.0\n",
      "Dupatta                      37.5     100.0\n",
      "Accessory Gift Set           97.1     100.0\n",
      "Cufflinks                   100.0     100.0\n",
      "Kajal and Eyeliner            0.0       0.0\n",
      "Kurta Sets                  100.0     100.0\n",
      "Free Gifts                   30.0      30.0\n",
      "Stoles                        0.0      22.2\n",
      "Duffel Bag                   82.1      92.9\n",
      "Bangle                        0.0      75.0\n",
      "Laptop Bag                   66.7      95.2\n",
      "Foundation and Primer         0.0       0.0\n",
      "Sports Sandals               86.4     100.0\n",
      "Bracelet                     87.5     100.0\n",
      "Lounge Pants                 23.1      61.5\n",
      "Face Moisturisers             0.0       0.0\n",
      "Jewellery Set               100.0     100.0\n",
      "Fragrance Gift Set            0.0       0.0\n",
      "Highlighter and Blush         0.0       0.0\n",
      "Boxers                        nan       nan\n",
      "Compact                       0.0       0.0\n",
      "Lip Liner                     0.0       0.0\n",
      "Mobile Pouch                 18.8      68.8\n",
      "Messenger Bag                15.0      85.0\n",
      "Eyeshadow                     0.0       0.0\n",
      "Suspenders                    nan       nan\n",
      "Camisoles                    20.8      79.2\n",
      "Mufflers                      0.0      90.5\n",
      "Patiala                       nan       nan\n",
      "Lounge Shorts                 0.0      25.0\n",
      "Jeggings                      nan       nan\n",
      "Stockings                    53.3      86.7\n",
      "Salwar                        nan       nan\n",
      "Churidar                      0.0      66.7\n",
      "Tracksuits                   77.8     100.0\n",
      "Face Wash and Cleanser        0.0       0.0\n",
      "Sunscreen                     0.0       0.0\n",
      "Shoe Accessories              0.0      25.0\n",
      "Bath Robe                     0.0       0.0\n",
      "Gloves                       40.0     100.0\n",
      "Hair Colour                   0.0       0.0\n",
      "Rain Jacket                  50.0     100.0\n",
      "Swimwear                      0.0      37.5\n",
      "Waist Pouch                   0.0      91.7\n",
      "Lip Care                      0.0       0.0\n",
      "Baby Dolls                    0.0       0.0\n",
      "Travel Accessory              0.0      44.4\n",
      "Jumpsuit                      0.0     100.0\n",
      "Waistcoat                     0.0      83.3\n",
      "Basketballs                   0.0      87.5\n",
      "Mascara                       0.0       0.0\n",
      "Mask and Peel                 0.0       0.0\n",
      "Rompers                       nan       nan\n",
      "Booties                       nan       nan\n",
      "Concealer                     0.0       0.0\n",
      "Rucksacks                    37.5      75.0\n",
      "Water Bottle                100.0     100.0\n",
      "Shapewear                     0.0       0.0\n",
      "Tights                        0.0       0.0\n",
      "Footballs                    50.0      50.0\n",
      "Clothing Set                  nan       nan\n",
      "Blazers                       nan       nan\n",
      "Headband                      0.0     100.0\n",
      "Salwar and Dupatta            nan       nan\n",
      "Wristbands                    0.0      33.3\n",
      "Umbrellas                    33.3     100.0\n",
      "Eye Cream                     0.0       0.0\n",
      "Nail Essentials               0.0       0.0\n",
      "Body Lotion                   0.0       0.0\n",
      "Shrug                         0.0       0.0\n",
      "Toner                         0.0       0.0\n",
      "Nehru Jackets                 nan       nan\n",
      "Face Scrub and Exfoliator       0.0       0.0\n",
      "Robe                          0.0      33.3\n",
      "Lip Plumper                   0.0       0.0\n",
      "Beauty Accessory              0.0       0.0\n",
      "Makeup Remover                0.0      66.7\n",
      "Lehenga Choli                 nan       nan\n",
      "Hat                           0.0       0.0\n",
      "Tablet Sleeve                 nan       nan\n",
      "Trolley Bag                   nan       nan\n",
      "Lounge Tshirts                nan       nan\n",
      "Ties and Cufflinks            0.0       0.0\n",
      "Rain Trousers                 0.0     100.0\n",
      "Face Serum and Gel            0.0       0.0\n",
      "Key chain                     0.0       0.0\n",
      "Body Wash and Scrub           0.0       0.0\n",
      "Hair Accessory                nan       nan\n",
      "Ipad                          nan       nan\n",
      "Mens Grooming Kit             0.0       0.0\n",
      "Cushion Covers                nan       nan\n",
      "Shoe Laces                    0.0       0.0\n",
      "===========================================\n",
      "Average                      28.8      51.0\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun08_1557/model_epoch_12.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- epoch:  0\n",
      "Training loss: 4.105\n",
      "Validation loss: 3.881\n",
      "Validation accuracy: 0.112\n",
      "------------- epoch:  1\n",
      "Training loss: 2.938\n",
      "Validation loss: 2.724\n",
      "Validation accuracy: 0.266\n",
      "------------- epoch:  2\n",
      "Training loss: 2.264\n",
      "Validation loss: 2.752\n",
      "Validation accuracy: 0.249\n",
      "------------- epoch:  3\n",
      "Training loss: 1.971\n",
      "Validation loss: 2.597\n",
      "Validation accuracy: 0.304\n",
      "------------- epoch:  4\n",
      "Training loss: 1.759\n",
      "Validation loss: 2.483\n",
      "Validation accuracy: 0.293\n",
      "------------- epoch:  5\n",
      "Training loss: 1.607\n",
      "Validation loss: 2.270\n",
      "Validation accuracy: 0.346\n",
      "------------- epoch:  6\n",
      "Training loss: 1.355\n",
      "Validation loss: 2.489\n",
      "Validation accuracy: 0.332\n",
      "------------- epoch:  7\n",
      "Training loss: 1.285\n",
      "Validation loss: 2.237\n",
      "Validation accuracy: 0.328\n",
      "------------- epoch:  8\n",
      "Training loss: 1.158\n",
      "Validation loss: 2.540\n",
      "Validation accuracy: 0.353\n",
      "------------- epoch:  9\n",
      "Training loss: 1.058\n",
      "Validation loss: 2.576\n",
      "Validation accuracy: 0.349\n",
      "------------- epoch:  10\n",
      "Training loss: 1.032\n",
      "Validation loss: 2.606\n",
      "Validation accuracy: 0.342\n",
      "------------- epoch:  11\n",
      "Training loss: 1.054\n",
      "Validation loss: 2.528\n",
      "Validation accuracy: 0.325\n",
      "------------- epoch:  12\n",
      "Training loss: 0.948\n",
      "Validation loss: 2.695\n",
      "Validation accuracy: 0.309\n",
      "------------- epoch:  13\n",
      "Training loss: 0.947\n",
      "Validation loss: 2.750\n",
      "Validation accuracy: 0.371\n",
      "------------- epoch:  14\n",
      "Training loss: 0.770\n",
      "Validation loss: 2.933\n",
      "Validation accuracy: 0.372\n",
      "------------- epoch:  15\n",
      "Training loss: 0.819\n",
      "Validation loss: 2.872\n",
      "Validation accuracy: 0.358\n",
      "------------- epoch:  16\n",
      "Training loss: 0.758\n",
      "Validation loss: 2.626\n",
      "Validation accuracy: 0.388\n",
      "------------- epoch:  17\n",
      "Training loss: 0.706\n",
      "Validation loss: 2.712\n",
      "Validation accuracy: 0.393\n",
      "------------- epoch:  18\n",
      "Training loss: 0.681\n",
      "Validation loss: 3.680\n",
      "Validation accuracy: 0.268\n",
      "------------- epoch:  19\n",
      "Training loss: 0.614\n",
      "Validation loss: 2.905\n",
      "Validation accuracy: 0.402\n"
     ]
    }
   ],
   "source": [
    "model.fc = nn.Linear(num_ftrs, 20)\n",
    "best_checkpoint = torch.load('traces/gpu_0_Jun08_1520/model_epoch_14.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "num_ftrs = model.fc.in_features\n",
    "## replacing the last layer with the dense layer we need\n",
    "model.fc = nn.Linear(num_ftrs, data.n_classes)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(weight=torch.tensor(data.weights).float().cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "fewshot.trainer.run_training(model, 20, data, optimizer, loss_func, gpu_id=0, root='./traces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category                    Top-1     Top-5\n",
      "-------------------------------------------\n",
      "Shorts                       23.3      90.7\n",
      "Trousers                     86.0      97.7\n",
      "Flats                        73.8      97.6\n",
      "Bra                          47.6      97.6\n",
      "Dresses                      29.7      78.4\n",
      "Sarees                        nan       nan\n",
      "Earrings                     90.9     100.0\n",
      "Deodorant                     0.0       0.0\n",
      "Nail Polish                   0.0       0.0\n",
      "Lipstick                      0.0       0.0\n",
      "Track Pants                  53.5      88.4\n",
      "Clutches                     36.4      90.9\n",
      "Sweatshirts                  32.6      93.0\n",
      "Caps                         82.5      82.5\n",
      "Sweaters                     60.5      83.7\n",
      "Ties                         85.3      88.2\n",
      "Jackets                      44.2      81.4\n",
      "Innerwear Vests               0.0       0.0\n",
      "Kurtis                       48.6      97.1\n",
      "Tunics                       19.2      92.3\n",
      "Nightdress                   47.6      95.2\n",
      "Leggings                     34.6      84.6\n",
      "Pendant                      50.0      97.1\n",
      "Capris                       33.3     100.0\n",
      "Necklace and Chains          66.7     100.0\n",
      "Lip Gloss                     0.0       0.0\n",
      "Night suits                  31.2      75.0\n",
      "Trunk                         nan       nan\n",
      "Skirts                       61.3      64.5\n",
      "Scarves                      32.0      80.0\n",
      "Ring                         85.0     100.0\n",
      "Dupatta                      37.5      75.0\n",
      "Accessory Gift Set          100.0     100.0\n",
      "Cufflinks                   100.0     100.0\n",
      "Kajal and Eyeliner            0.0       0.0\n",
      "Kurta Sets                  100.0     100.0\n",
      "Free Gifts                    0.0      30.0\n",
      "Stoles                       33.3      44.4\n",
      "Duffel Bag                   50.0      92.9\n",
      "Bangle                        5.0      80.0\n",
      "Laptop Bag                   52.4      90.5\n",
      "Foundation and Primer         0.0       0.0\n",
      "Sports Sandals               72.7      95.5\n",
      "Bracelet                     93.8     100.0\n",
      "Lounge Pants                  7.7      46.2\n",
      "Face Moisturisers             0.0       0.0\n",
      "Jewellery Set                90.9      90.9\n",
      "Fragrance Gift Set            0.0       0.0\n",
      "Highlighter and Blush         0.0       0.0\n",
      "Boxers                        nan       nan\n",
      "Compact                       0.0       0.0\n",
      "Lip Liner                     0.0       0.0\n",
      "Mobile Pouch                 37.5      75.0\n",
      "Messenger Bag                50.0      95.0\n",
      "Eyeshadow                     0.0       0.0\n",
      "Suspenders                    nan       nan\n",
      "Camisoles                    58.3      95.8\n",
      "Mufflers                     85.7      90.5\n",
      "Patiala                       nan       nan\n",
      "Lounge Shorts                 0.0      37.5\n",
      "Jeggings                      nan       nan\n",
      "Stockings                    46.7      80.0\n",
      "Salwar                        nan       nan\n",
      "Churidar                     33.3      33.3\n",
      "Tracksuits                   88.9      94.4\n",
      "Face Wash and Cleanser        0.0       0.0\n",
      "Sunscreen                     0.0       0.0\n",
      "Shoe Accessories              6.2      31.2\n",
      "Bath Robe                     0.0       0.0\n",
      "Gloves                       40.0     100.0\n",
      "Hair Colour                   0.0       0.0\n",
      "Rain Jacket                  50.0     100.0\n",
      "Swimwear                     12.5      37.5\n",
      "Waist Pouch                   8.3      83.3\n",
      "Lip Care                      0.0       0.0\n",
      "Baby Dolls                    0.0       0.0\n",
      "Travel Accessory             11.1      22.2\n",
      "Jumpsuit                     50.0      50.0\n",
      "Waistcoat                     0.0      83.3\n",
      "Basketballs                  37.5     100.0\n",
      "Mascara                       0.0       0.0\n",
      "Mask and Peel                 0.0       0.0\n",
      "Rompers                       nan       nan\n",
      "Booties                       nan       nan\n",
      "Concealer                     0.0       0.0\n",
      "Rucksacks                   100.0     100.0\n",
      "Water Bottle                100.0     100.0\n",
      "Shapewear                     0.0     100.0\n",
      "Tights                      100.0     100.0\n",
      "Footballs                    50.0      50.0\n",
      "Clothing Set                  nan       nan\n",
      "Blazers                       nan       nan\n",
      "Headband                     66.7     100.0\n",
      "Salwar and Dupatta            nan       nan\n",
      "Wristbands                   66.7     100.0\n",
      "Umbrellas                   100.0     100.0\n",
      "Eye Cream                     0.0       0.0\n",
      "Nail Essentials               0.0       0.0\n",
      "Body Lotion                   0.0       0.0\n",
      "Shrug                         0.0       0.0\n",
      "Toner                         0.0       0.0\n",
      "Nehru Jackets                 nan       nan\n",
      "Face Scrub and Exfoliator       0.0       0.0\n",
      "Robe                          0.0       0.0\n",
      "Lip Plumper                   0.0       0.0\n",
      "Beauty Accessory              0.0       0.0\n",
      "Makeup Remover                0.0      33.3\n",
      "Lehenga Choli                 nan       nan\n",
      "Hat                           0.0       0.0\n",
      "Tablet Sleeve                 nan       nan\n",
      "Trolley Bag                   nan       nan\n",
      "Lounge Tshirts                nan       nan\n",
      "Ties and Cufflinks            0.0       0.0\n",
      "Rain Trousers               100.0     100.0\n",
      "Face Serum and Gel            0.0       0.0\n",
      "Key chain                     0.0       0.0\n",
      "Body Wash and Scrub           0.0       0.0\n",
      "Hair Accessory                nan       nan\n",
      "Ipad                          nan       nan\n",
      "Mens Grooming Kit             0.0       0.0\n",
      "Cushion Covers                nan       nan\n",
      "Shoe Laces                    0.0       0.0\n",
      "===========================================\n",
      "Average                      32.3      51.9\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = torch.load('traces/gpu_0_Jun08_1617/model_epoch_1.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "c1, c5, occ = fewshot.trainer.evaluate(model.cuda(), data, 0, data.n_classes)\n",
    "fewshot.trainer.pretty_print_eval(c1, c5, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare this to not finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fewshot.data.FashionData('../data/small/styles_quoted.csv',\n",
    "                                '../data/small/images/',\n",
    "                               train_transform=train_transform,\n",
    "                               test_transform=test_transform,\n",
    "                               top20=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(data.idx2name)\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "## replacing the last layer with the dense layer we need\n",
    "model.fc = nn.Linear(num_ftrs, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot.trainer.run_training(model, 5, data, optimizer, loss_func, gpu_id=0, root='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
